\section{Proposed Project}.

Amongst the source extension options described in the previous section, only the surface extension has all of these properties:
\begin{itemize}
\item requires only additional storage roughly equivalent to the data volume
\item does not require prior knowledge of the source wavelet, in fact recovers an estimate as a by-product
\item inner problem (in variable projection - estimation of the extended source) has a cheap approximate solution, via back-propagation
\item relation with traveltime inversion persists, regardless of ray geometry
\end{itemize}

Therefoire I propose that we begin with a time-domain implementation of the surface source extension.

\section{Detailed Description}
The simplest version of the surface source extension assumes acoustic wave physics, and that the physical source locations lie on the horizontal surface $z=z_s$. The coefficient vector $c$ is the pair $(\kappa,\beta)$ of bulk modulus and buoyancy, and the wave operator $L[c]$ is given by the linear acoustics system:
\begin{eqnarray}
\label{eqn:awe}
\frac{\partial p}{\partial t} & = & - \kappa (\nabla \cdot \bv +
w(t)\delta(\bx-\bx_s)), \nonumber \\
\frac{\partial \bv}{\partial t} & = & - \beta \nabla p,\nonumber \\
p & =& 0 \mbox{ for } t<0\nonumber\\ 
\bv & = & 0 \mbox{ for } t<0 
\end{eqnarray}
The physical source is modeled as an isotropic point constitutive law defect. As mentioned earlier, it is simple to accommodate more complex source models.

The dynamical field is the 4-tuple $u=(p,\bv)$. Either the pressure $p$ or the particle velocity $\bv$ could be sampled (or both) - presume that the pressure is sampled, that is $Pu = \{p(\bx_r,t;\bx_s)\}$, where $\{\bx_r\}$ are the receiver positions. 

Extended sources are spread over $z=z_s$ (\ref{eqn:mssur}). The annihilator is the source localization penalty, equation \ref{eqn:msste}.

Denote by $J_{\alpha}[g,c;d]$ the objective function defined in \ref{eqn:esi}:
\begin{equation}
\label{eqn:jdef}
J_{\alpha}[g,c;d] = \frac{1}{2}( \|PL[c]^{-1}g -d \|^2 + \alpha \|A[g]\|^2) 
\end{equation}
To compute the objective 
\begin{itemize}
\item solve the acoustic wave system \ref{eqn:awe} with $g$ as in \ref{eqn:mssur}
\item sample at receiver locations and compute mean-square difference with pressure data traces, take mean square
\item add scaled mean square of annihilator applied to the source
\end{itemize}

The variable projection method \cite[]{GolubPereyra:03} applied to the objective \ref{eqn:esi} approaches its minimization via a nested algorithm: first minimize \ref{eqn:esi} over the source $g$ for given coefficients $c$, thus making $g = g[c]$ a function of $c$ (inner minimization); then substitute $g[c]$ in $J$ and minimize the resulting function of $c$ (outer minimization). The optimal $g[c]$ solves the first order necessary condition for minimization of $J$ over $g$: $\nabla_g J_{\alpha}[g,c;d] = 0$. For linear annihilators such as that defined by \ref{eqn:mssur}, $J$ is quadratic in $g$, so the first order necessary condition is also sufficient, and is equivalent to the linear {\em normal equation}:
\begin{equation}
\label{eqn:normal}
(S[c]^TS[c] + \alpha A^TA) g = S[c]^T d
\end{equation}
where I have written $S[c]=PL[c]^{-1}$ for the operator that maps the (extended) source to the data traces. Substitution of $g[c]$ in $J$ results in the {\em reduced objective}
\begin{equation}
\label{eqn:jred}
\tilde{J}_{\alpha}[c;d] = J_{\alpha}[g[c],c;d].
\end{equation}
The gradient would appear to involve the derivative of the inner solution $g[c]$ with respect to $c$, computation of which implies solution of additional linear systems. However by fortunate accident, the chain rule and the normal equation \ref{eqn:normal}
conspire to eliminate all terms involving derivatives of $g[c]$. Consequently the direction derivative of $\tilde{J}_{\alpha}$ in the direction $\delta c$ is
\begin{equation}
\label{eqn:tildejderiv}
D_c\tilde{J}_{\alpha}[c;d]\delta c = \langle D(S[c]g)\delta c,S[c]g-d \rangle|_{g=g[c]}
\end{equation}
whence
\begin{equation}
\label{eqn:l2grad}
\nabla \tilde{J}_{\alpha}[c;d] = D_c(S[c]g)^T|_{g=g[c]}(S[c]g[c]-d)
\end{equation}
Let us field-strip the expression on the right. The rightmost factor is the data residual, which is a by-product of many methods for the solution of the normal equation \ref{eqn:normal}. $D_cS$ is the linearization or Born approximation of $S$, or perturbation with respect to $c$, with $g$ fixed:
\[
S[c+\delta c]g \approx S[c]g + D_c(S[c]g)\delta c
\]
That is, $D_c(S[c]g)$ is the object commonly called the Born modeling operator, with source wavefield $g$. Its adjoint or transpose is $D_c(S[c]g)^T$ - as is well known, this is the RTM operator (or rather a version of it), computed via the adjoint state method in the time domain. Note that the Born and RTM operators need to match, i.e. both be derived from the same underlying full waveform modeling operator (in this case acoustodynamics, but the same would apply for any other wave theory).

The upshot is that the computation of the gradient goes like this:
\begin{itemize}
\item solve the normal equation \ref{eqn:normal} for $g[c]$
\item compute (or retain) the data residual $S[c]g[c]-d$
\item reverse-time migrate the data residual, using $g[c]$ to generate the source wavefield in the adjoint state method - the output is the gradient of $\tilde{J}_{\alpha}$.
\end{itemize}

To make this algorithm practical and efficient, effective preconditioning needs to be applied to both inner and outer problems.

\subsection{Preconditioning the Outer Problem: Gradient Smoothing}
Conditioning the outer (velocity etc.) update has different meaning for transmission versus reflection problems. One interpretation of ``transmission'' is that no reflection occurs on any ray path connecting source and receiver, whereever these may be located. Is is practically implicit in the use of ``ray path'' in this statement that the material model is at least mostly smooth, or essentially localized in low spatial frequencies. Smoothness is also one way to interpret ``lack of reflections''. The classic work explaining the need for model smoothness in tomography is \cite{DelpratLailly:92}. Since the surface source extension method gets its ability to identify kinematically correct velocity from its relation to tomography, it also requires model smoothness, at least for transmission.

A natural method for enforcing smoothness is use of a norm in model space that penalizes lack of smoothness. This method is also properly called preconditioning, which consists in altering the choice of norm to enhance convergence. For pure transmission, the choice recommended by \cite[]{DelpratLailly:92} is a norm from the Sobolev family. These are weighted $L^2$ (RMS) norms with weight operators indexed by a real parameter $s$:
\begin{equation}
\label{eqn:sob}
\|u\|^2_s = \langle u, W_s u \rangle_{L^2},\,\,W_s = (I - \nabla^2)^s
\end{equation}
Choosing $s>0$ penalizes lack of smoothness. According to the Sobolev Embedding Theorem and the basic well-posedness theorem for ordinary differential equations (which governs the behaviour of the ray system), it is neccessary to choose $s > 2 + d/2$ in dimension $d$, in order that metrizing the velocity (amongst other things) with the $s$-norm will guarantee sufficient smoothness that ray theory is well-behaved, and the link with tomography honored. For both $d=2$ and $d=3$, $s=4$ would work.

The gradient of a function is defined with respect to the domain norm. Using the $s$-norm, the gradient is
\begin{equation}
\label{eqn:grads}
\nabla_s \tilde{J}_{\alpha}[c,d] = W_s^{-1}\nabla \tilde{J}_{\alpha}[c,d]
\end{equation}
If $s>0$ then $W_s^{-1}$ is a smoothing operator. It is best implemented in the Fourier domain.

The most natural way view the reflection problem is to allow non-smoothness in $c$. It is not clear at this point what would be the optimal choice of weight operator in this case, or even whether there is a choice of Hilbert space structure that would offer an easily computable gradient and development of short-scale structures to generate reflections. GH used very low frequency data (in frequency domain) and Tihonov regularization. His results seemed to depend heavily on the regularization weight. Of course we also do not know how to connect the reflection case to a tomographic principle, so have no guidance for how a model space norm should be selected. These are the main target questions of this project.

\subsection{Preconditioning the Inner Problem: Time Reversal}
%In contrast to the outer problem, a preconditioner for the inner problem is available that works regardless of medium smoothness, so for both transmission and reflection (the latter with some caveats). 
In contrast to the outer problem, the inner problem admits a conventional preconditioner, that is, a change of variables that in the spaces of source traces and data traces respectively that moves the singular values of the modeling operator closer to 1. This preconditioner also creates an approximate solution operator for the inner problem, of the form
\begin{equation}
\label{eqn:appinv}
S[c]^{\dagger} = W_m[c]^{-1}S[c]^TW_d[c],
\end{equation}
in which $W_m$ and $W_c$ are $c$-dependent positive definite symmetric operators that define weighted inner products in domain and range of $S[c]$, and their associated weighted norms:
\begin{eqnarray}
\label{eqn:norms}
\langle f,g \rangle_m & = & \langle f, W_mg\rangle; \|f\|_m^2 = \langle f,f\rangle_m \nonumber \\
\langle f,g \rangle_d & = & \langle f, W_d g\rangle; \|f\|_d^2 = \langle f,f \rangle_d
\end{eqnarray}
We have implicitly used the notations $\langle \cdot,\cdot \rangle, \|\cdot \|$ (without subscripts) to denote the (unweighted) $L^2$ norm, in whatever form is appropriate for the arguments. That is what these symbols mean in display \ref{eqn:norms}, and will continue to mean.

The approximate inverse $S[c]^{\dagger}$ defined by the relation \ref{eqn:appinv} is the transpose of $S[c]$ with respect to the inner products $\langle \cdot,\cdot \rangle_m,, \langle \cdot,\cdot \rangle_d$, so $S[c]$ is approximately unitary in the same sense. Consequently the singular spectrum (which is also dependent on choice of inner product) is close to that of the identity - or most of it is, as we shall explain - and the convergence of  a Krylov subspace method like Conjugate Gradient (CG) Iteration converge relatively rapidly. 

The system that needs solving, of course, is the normal equation \ref{eqn:normal},  so it is the convergence of CG or the like applied to that system that is the important issue. The normal equation is the first order necessary condition for minimization of the objective
\begin{equation}
\label{eqn:jdefs}
J_{\alpha}[g,c;d] = \frac{1}{2}( \|S[c]g -d \|^2 + \alpha \|A[g]\|^2).
\end{equation}
over the choice of surface source $g$. The choice of norms appearing in \ref{eqn:jdefs} is actually arbitrary, and the norms appearing in the first and second terms on the right-hand side do not even have to be the same. 

%First the transmission case - a sort of rotated crosswell configuration. Idealize the receiver set as a continuum plane $z=z_r$, with $z_r > z_s$ - not essential but simpler. 

%Two key facts and a geometric assumption underly the construction of the time-reversal preconditioner: (i) a local relation between the surface source and the normal particle velocity, and (ii) the uniqueness of solutions of the Dirichlet boundary value problem for the wave equation. Together these facts allow us to reconstruct the pressure field, or the significant part of it, from the transmission data, and to approximate a distributed source responsible for a given set of data traces.

%The geometric assumption is that the pressure field is {\em outgoing} at the recording datum: that is, that it is the restriction to $z>z_s$ of a pressure field that is negligible in $z<z_r$ for large enough time. ``Negligible'', rather than vanishing, as the latter is strictly speaking impossible: this property is asymptotic in frequency, and assured by an assumption about the ray field associated to the acoustic system. 

%NB: the definition of the forward map (and the data) should include a taper $\phi(\bx_r,\bx_s)$ masking out the shot gather $d_r(\cdot,\cdot;\bx_s)$ for each source position $\bx_s$. However I will not explicitly mention this operation. I will also ignore it in the numerical examples, but there will be a price to pay.

To begin with, change notation slightly, and write $S[c]h_s$ rather than $S[c]g$ with $g = h_s \delta(z-z_s)$, as $z_s$ will be presumed ot be the same for all shots. 
%The addition of the subscript indicates that the sources lie on the plane $z=z_s$ and the receivers are on the plane $z=z_r$. As will be apparent shortly, a similar operator with source and receiver planes swapped will also be important, hence the need for the additional information in the notation.

The pressure and velocity fields occuring in the computation of $d_r=p|_{z=z_r}=S[c]_{s,r}h_s$ form the solution of
\begin{eqnarray}
\label{eqn:awedata}
\frac{\partial p}{\partial t} & = & - \kappa( \nabla \cdot \bv +
h \delta(z-z_s)), \nonumber \\
\frac{\partial \bv}{\partial t} & = & - \beta \nabla p,\nonumber \\
p & =& 0 \mbox{ for } t \ll 0 \nonumber\\ 
\bv & = & 0 \mbox{ for } t \ll 0 \nonumber\\
\end{eqnarray}
Actually $p,\bv$ form a {\em weak solution} of the system \ref{eqn:awedata}, defined by integration by parts. A more general setting for this type of system provides an advantageous framework within which to explain the properties of these weak solutions.

Let $\omega \subset \bR^d$ be a smooth orientable surface. Then the distribution $\delta_{\omega}$ is well-defined: for $u \in C_0^{\infty}(\bR^d)$, 
\[
\langle \delta_{\omega}, u \rangle = \int_{\omega} u dS
\]
The system \ref{eqn:awedata} is a special case of
\begin{eqnarray}
\label{eqn:aweomega}
\frac{\partial p}{\partial t} & = & - \kappa( \nabla \cdot \bv +
h \delta_{\omega}, \nonumber \\
\frac{\partial \bv}{\partial t} & = & - \beta \nabla p,\nonumber \\
p & =& 0 \mbox{ for } t \ll 0 \nonumber\\ 
\bv & = & 0 \mbox{ for } t \ll 0 \nonumber\\
\end{eqnarray}
in which $h \in C_0^{\infty}(\omega)$.

\begin{thm}
\label{thm:bvs}
Suppose that $\kappa,\beta$ are smooth. Then the system \ref{eqn:aweomega} has a unique weak solution $(p,\bv)$. Denote by $[v_n] \in C^{\infty}(\omega)$ the jump of the normal component of $\bv$ across $\omega$:
\[
[v_n](\bx) = \lim_{\epsilon \rightarrow 0} (\bv(\bx + \epsilon {\bf n}(\bx))-\bv(\bx - \epsilon {\bf n}(\bx)))\cdot {\bf n}(\bx),\,\bx \in \omega.
\]
Then $h(\bx) = [v_n](\bx), \bx \in \omega$.

%Let $p,\bv$ be the weak solution of the system \ref{eqn:awedata}, and assume that $\kappa, \beta$ are smooth. Denote by $[v_z]|_{z=z_s}$ the jump of the z-component of particle velocity in the z-direction:
%\[
%[v_z](x,z) = v_z^+(x,z)-v_z^-(x,z),  v_z^{\pm}(x,z)=\lim_{z'\rightarrow z^{\pm}} v_z(x,z')
%\]
%Then $[v_z](x,z)=0$ unless $z=z_s$, and
%\[
%h(x) = [v_z](x,z_s).
%\]
\end{thm}
For the proof, see  Appendix B.

For the rest of this section, $\omega$ will be a coordinate hyperplane, defined by $z=$ constant, with its usual orientation, and I will write $[v_z] = [v_b]$.

To begin with, change notation slightly, and write $S[c]h_s$ rather than $S[c]g$ with $g = h_s \delta(z-z_s)$, as $z_s$ will be presumed ot be the same for all shots. 
%The addition of the subscript indicates that the sources lie on the plane $z=z_s$ and the receivers are on the plane $z=z_r$. As will be apparent shortly, a similar operator with source and receiver planes swapped will also be important, hence the need for the additional information in the notation.

The pressure and velocity fields occuring in the computation of $d_r=p|_{z=z_r}=S[c]_{s,r}h_s$ form the solution of
\begin{eqnarray}
\label{eqn:awedata1}
\frac{\partial p}{\partial t} & = & - \kappa( \nabla \cdot \bv +
h \delta(z-z_s)), \nonumber \\
\frac{\partial \bv}{\partial t} & = & - \beta \nabla p,\nonumber \\
p & =& 0 \mbox{ for } t \ll 0 \nonumber\\ 
\bv & = & 0 \mbox{ for } t \ll 0 \nonumber\\
\end{eqnarray}
Actually $p,\bv$ form a {\em weak solution} of the system \ref{eqn:awedata1}, defined by integration by parts.
\begin{thm}
\label{thm:vz2}
If $\kappa,\beta$ are constant near the $z=z_s$, then $v_z^-=-v_z^+$ so $[v_z] = 2 v_n^+$. 
\end{thm}
(for proof see Appendix 2). The formulation is for 2D propagation, but a precisely similar fact is true for 3D - in that case, $x$ is replaced everywhere by the horizontal coordinates.

The import of Theorem \ref{thm:bvs} is that we can read off the source if we can infer the (particle) velocity field near the source surface, from knowledge of the data traces (values of the pressure at $z=z_r$). The key observation that enables this feat is a well-posedness theorem for the wave equation:

\begin{thm} \label{thm:bvp}
Suppose that $\omega \subset \bR^d$ is a smooth orientable surface, $\omega = \partial  \Omega^- = \partial \Omega^+$, where $\Omega^{\pm}$ are the open exterior/interior regions defined by the outward unit normal field of $\omega$, and let $d \in C^{\infty}_0(\omega \times \bR)$. Then there exist unique smooth solutions $p^{\pm},\bv^{\pm}$ of the initial/boundary value problems 
\begin{eqnarray}
\label{eqn:awebdry}
\frac{\partial p^{\pm}}{\partial t} & = & - \kappa \nabla \cdot \bv^{\pm} \mbox{ in } \Omega^{\pm}, \nonumber \\
\frac{\partial \bv^{\pm}}{\partial t} & = & - \beta \nabla p^{\pm} \mbox{ in } \Omega^{\pm},\nonumber \\
p^{\pm} & =& 0 \mbox{ for } t \ll 0\nonumber\\ 
\bv^{\pm} & = & 0 \mbox{ for } t \ll 0 \nonumber\\
\lim_{\bx \rightarrow \omega^{\pm}}p & = & d 
\end{eqnarray}
\end{thm}


Putting the two theorems together, obtain
\begin{cor}\label{thm:bvps}
Suppose that $d_s$ is a sufficiently regular function, = 0 for $t<0$, and denote by $p^{\pm},\bv^{\pm}$ the half-space solutions provided by Theorem \ref{thm:bvp}. Define the vector fields $p,\bv$ in $\bR^4$ by
\begin{eqnarray}
\label{eqn:putemtogether} 
p(x,z) &=& p^{\pm}(x,z) \mbox{ for } \pm(z-z_s) > 0\\
p(x,z_s)&=&d_s(x)\\
\bv(x,z) &=& \bv^{\pm}(x,z) \mbox{ for } \pm(z-z_s) > 0\\
\end{eqnarray}
Then $p,\bv$ is a weak solution of the system \ref{eqn:awedata1} with $h=[v]_n$.
\end{cor}

Now invoke the {\em outgoing assumption}: $p,\bv$ is the restriction to $z>z_s$ of a solution vanishing in $z<z_r$ for large $t$. This condition needs to be interpreted asymptotically, that is, $p,\bv$ is relatively smooth (lower order in frequency) for $t \gg 0, z<z_r$. It holds if the rays carrying significant energy in $p,\bv$ intersect $z=z_r$ transversally, and do not return to $z<z_r$ in forward time. The examples below will satisfy this condition, because the wave velocity is constant in $z > z_r$.

Note that isotropic point sources do not produce fields outgoing in a half space, in the sense just described - simply because they radiate in all directions. However, for any specified finite time of propagation, it is possible to replace a point source by an anisotropic source that fits the point source data to within an arbitrarily small error, and does produce outgoing fields. In fact, the numerical examples below will construct such sources. 

This assumption implies that for $t$ sufficiently large, $d_r = p|_{z=z_r}$ is negligible for $t \gg 0$, so $p,\bv$ differs in $z_s<z < z_r$ by a negligible error from the solution of $p^-,\bv^-$, part of the solution of the  backwards-in-time  initial value problem, similar to the system \ref{eqn:awebdry}:
\begin{eqnarray}
\label{eqn:awetr}
\frac{\partial \tilde{p}^{\pm}}{\partial t} & = & - \kappa \nabla \cdot \tilde{\bv}^{\pm}, \pm(z-z_r)>0 \nonumber \\
\frac{\partial \tilde{\bv}^{\pm}}{\partial t} & = & - \beta \nabla \tilde{p}^{\pm},\nonumber \\
\tilde{p}^{\pm} & =& 0 \mbox{ for } t \gg 0,\nonumber\\ 
\tilde{\bv}{\pm} & = & 0 \mbox{ for } t \gg 0,\nonumber\\
\lim_{z \rightarrow z_r^{\pm}}\tilde{p}^{\pm} &=&  d_r, \nonumber\\,
\tilde{p} &=& \tilde{p}^{\pm}, \pm(z-z_r)>0, \nonumber\\, 
\tilde{\bv} &=& \tilde{\bv}^{\pm}, \pm(z-z_r)>0.
\end{eqnarray} 

This must be so, as $p,\bv$ satisfies the wave equation system (first two conditions), and the rest as well except for a negligible error. The last condition must be interpreted consistently, that is $\tilde{p}=0$ for $t$ large enough that $d_r$ is negligible. (In practice consistency will be obtained by replacing $t \gg 0$ respectively $t \ll \infty$ by $t > t_{\rm max}$, $t < t_{\rm max}$ for a suitably large $t_{\rm max}$). Then the standard energy estimate shows that $p, \tilde{p}$ differ also by a negligible error: in particular, $p|_{z=z_s} \approx \tilde{p}_{z=z_s}$.

According to Corollary \ref{thm:bvps}, recovering $p_{z=z_s}$ entails recovering $h_s=[v_z]|_{z=z_s}$. So a procedure for computing an approximate inverse $S[c]_{s,r}^{\dagger}$ for $S[c]_{s,r}$ is 
\begin{equation}
\label{eqn:psinv}
S[c]_{s,r}^{\dagger}d_r\equiv [v_z]_{z=z_s}.
\end{equation}
where the jump in $v_z$ at $z=z_s$ is computed from knowledge of $d_r=p|_{z=z_r}$ by
\begin{itemize}
\item solving \ref{eqn:awetr} backwards in time,
\item reading off $d_s=\tilde{p}$ at $z=z_s$,
\item solving \ref{eqn:awebdry} forwards in time, and computing $[v_z]|_{z=z_s}$, or if appropriate ($\kappa$ and $\beta$ constant near $z=z_s$) simply using $\bar{v}_{z=z_s^+} = v_z^{+}=-v_z^{-}$ at $z=z_s$ (Theorem \ref{thm:bvs}).
\end{itemize}

The relations developed in the last few paragraphs may be summarized as follows:
\begin{equation}
\label{eqn:appinv}
d_r = S[c]_{s,r}h_s \,\,\Leftrightarrow \,\, h_s \approx S[c]_{s,r}^{\dagger}d_r
\end{equation}
that is, $S[c]_{s,r}^{\dagger}$ is an approximate inverse of $S[c]_{s,r}$.

Inspection of systems \ref{eqn:awebdry} and \ref{eqn:awetr} reveals that they are actually the same, except for the direction of time, and that observation leads to another useful relation. Denote by $R$ the time-reversal operator:
\[
Ru(\bx,t)=u(\bx,-t)
\]
and by {\cal R} the time reversal operator for acoustic fields:
\[
{\cal R}\left(\begin{array}{c}
p\\
\bv
\end{array}
\right) = 
\left(\begin{array}{c}
Rp\\
-R\bv
\end{array}
\right) 
\]
The sign in the definition of ${\cal R}$ is chosen so that if $(\tilde{p},\tilde{\bv})^T$ solves the system \ref{eqn:awetr}, then ${\cal R}(\tilde{p},\tilde{\bv})^T=(\hat{p},\hat{\bv})^T$ is the solution of 
\begin{eqnarray}
\label{eqn:awetrs}
\frac{\partial \hat{p}^{\pm}}{\partial t} & = & - \kappa \nabla \cdot \hat{\bv}^{\pm}, \pm(z-z_r) > 0 \nonumber \\
\frac{\partial \hat{\bv}^{\pm}}{\partial t} & = & - \beta \nabla \hat{p}^{\pm},\nonumber \\
\hat{p}^{\pm} & =& 0 \mbox{ for } t \ll 0,\nonumber\\ 
\hat{\bv}^{\pm} & = & 0 \mbox{ for } t \ll 0,\nonumber\\
\lim _{z=z_r^{\pm}}\hat{p}^{\pm} &=&  Rd_r,\nonumber\\
\hat{p} &=& \hat{p}^{\pm}, \pm(z-z_r)>0, \nonumber\\, 
\hat{\bv} &=& \hat{\bv}^{\pm}, \pm(z-z_r)>0.
\end{eqnarray} 

%For a smooth orientable surface $\omega$, denote by $\Lambda[c,\omega]$ the operator that maps Dirichlet pressure data $d$ on $\omega \times \bR$ to the jump in normal velocity $[v_n]$ across $\omega \times \bR$ via solution of the system \ref{eqn:awebdry}.

 From Corollary \ref{thm:bvps} applied to the system \ref{eqn:awetrs}, $\hat{p}|_{z=z_s} = S[c]_{r,s}\Lambda[c]_rRd_r$. Denote by $\Lambda[c]_r$ the same operator with $z_s$ replaced by $z_r$. Then $\hat{p}|_{z=z_s} = S[c]_{r,s}\Lambda[c]_rRd_r=R\tilde{p}|_{z=z_s}$. Thus the definition \ref{eqn:psinv} implies
\begin{equation}
\label{eqn:psinvrev}
S[c]_{s,r}^{\dagger}= -\Lambda[c]_sRS[c]_{r,s}R\Lambda[c]_r
\end{equation}
since $\Lambda[c]_rR=-R\Lambda[c]_r$ from the definition of ${\cal R}$.
Define $T[c]_{s,r}d_s = p|_{z=z_r}$ for the solution of \ref{eqn:awebdry}. Since ${\cal R}^2=I$, Then $\hat{p}|_{z=z_s} = T[c]_{r,s}Rd_r$. Since ${\cal R}^2=I$, ${\cal R}(\hat{p},\hat{\bv})^T=(\tilde{p},\tilde{\bv})^T$, whence $\tilde{p}|_{z=z_s}=RT[c]_{r,s}Rd_r$.

Denote by $\Lambda[c]_s$ the operator that produces the jump in normal velocity $[v_z]=\lim_{z \rightarrow z_s^+}v_z^+ - \lim_{z\rightarrow z_s^-} v_z^-$ from Dirichlet pressure data $d_s$ and causal solution of the system \ref{eqn:awebdry}. From Corollary \ref{thm:bvps}, $T[c]_{s,r} = S[c]_{s,r}\Lambda[c]_s$. Denote by $\Lambda[c]_r$ the same operator with $z_s$ replaced by $z_r$. Then $\hat{p}|_{z=z_s} = S[c]_{r,s}\Lambda[c]_rRd_r=R\tilde{p}|_{z=z_s}$. Thus the definition \ref{eqn:psinv} implies
\begin{equation}
\label{eqn:psinvrev}
S[c]_{s,r}^{\dagger}= -\Lambda[c]_sRS[c]_{r,s}R\Lambda[c]_r
\end{equation}
since $\Lambda[c]_rR=-R\Lambda[c]_r$ from the definition of ${\cal R}$.

As I will show in the example section, the approximation may be accurate enough without any further improvement. However, a closer examination shows that in fact it is possible to express the relation between $S[c]_{s,r}$ and $S[c]_{s,r}^{\dagger}$ in terms of a change of norm, that is, in terms of a preconditioner, and this relation can be used to considerably accelerate an iterative solution of the normal equation \ref{eqn:normal}. 

To see this, compute the formal or $L^2$ adjoint $S[c]_{s,r}^T$, by a variant of the adjoint state method, in this case a by-product of the conservation of energy. Suppose that $\bar{h}_r$ is a function on $z=z_r$ (data traces), and 
$\bar{p},\bar{\bv}$ solve the backwards-in-time boundary value problem:
\begin{eqnarray}
\label{eqn:aweadj}
\frac{\partial \bar{p}}{\partial t} & = & \kappa (-\nabla \cdot \bar{\bv} + 
 \bar{h}_r \delta(z-z_r))\nonumber \\
\frac{\partial \bar{\bv}}{\partial t} & = & - \beta \nabla \bar{p},\nonumber \\
\bar{p} & =& 0 \mbox{ for } t \gg 0\nonumber\\ 
\bar{\bv} & = & 0 \mbox{ for } t \gg 0 
\end{eqnarray} 
Then
\[
0 = 
\left(\int\, dx\,dy\,dz\, \frac{p \bar{p}}{\kappa} +  
\frac{\bv \cdot \bar{\bv}}{\beta} \right)|_{t=T}
-
\left(\int\, dx\,dy\,dz\, \frac{p \bar{p}}{\kappa} +  \frac{\bv \cdot \bar{\bv}}{\beta} \right)|_{t=0}
\]
\[
= 
\int_{0}^{T} \,dt\, \frac{d}{dt}\left(\int\, dx\,dy\,dz\, \frac{p \bar{p}}{\kappa} +  \frac{\bv \cdot \bar{\bv}}{\beta} \right)
\]
\[
= 
\int_{0}^{T} \,dt\, \left(\int\, dx\,dy\,dz\, \frac{1}{\kappa} \frac{\partial p}{\partial t} \bar {p} +  p \frac{1}{\kappa}\frac{\partial \bar{p}}{\partial t} \right.
\]
\[
+
\left. \frac{1}{\beta} \frac{\partial \bv}{\partial t} \cdot \bar{\bv} + \frac{1}{\beta} \bv \cdot \frac{\partial \bar{\bv}}{\partial t} \right)
\]
\[
= 
\int_{0}^{T} \,dt\, \left(\int\, dx\,dy\,dz\, \left(- \nabla \cdot \bv + 
 h_s \delta(z-z_s)\right) \bar{p} + p \left(- \nabla \cdot \bar{\bv} + 
 d_r \delta(z-z_r)\right) \right.
\]
\[
+
\left.  (- \nabla p) \cdot \bar{\bv} + \bv \cdot (-\nabla \bar{p}) \right)
\]
\[
= 
\int_{0}^{T}\,dt\, \left(\int\, dx\,dy\,dz\, \left(- \nabla \cdot \bv + 
 h_s \delta(z-z_s)\right) \bar{p} + p \left(- \nabla \cdot \bar{\bv} + 
 d_r \delta(z-z_r)\right) \right.
\]
\[
+
\left.  p (\nabla \cdot \bar{\bv}) + (\nabla \cdot \bv) \bar{p} \right)
\]
after integration by parts in the last two terms. Most of what is left cancels, leaving 
\[
0 = \int\,dt\,dx\,dy\, (h_s \bar{p})_{z=z_s} + (p  \bar{h}_r)_{z=z_r}
\]
whence
\begin{equation}
\label{eqn:sadj}
 S[c]_{s,r}^T \bar{h}_r = -\bar{p}|_{z=z_s}
\end{equation}
Compare the systems \ref{eqn:awetr} and \ref{eqn:aweadj}: they differ in that 
\begin{itemize}
\item in \ref{eqn:awetr}, $d_r$ appears as a Dirichlet condition on $z=z_r$,
\item in \ref{eqn:aweadj}, $\bar{h}_r$ appears as a distributed source on $z=z_r$.
\end{itemize}
According to Corollary \ref{thm:bvps}, $\bar{p}=\bar{p}, \bar{\bv}=\bar{\bv}$ if $\bar{h}_r = [\bar{v}_z]|_{z=z_r}$, i.e. the source is that which generates the same solution as the Dirichlet condition..

Simlarly denote by $\tilde{\Lambda}[c]_r$ the operator that produces the jump in normal velocity at $z=z_r$ from pressure data $d_r$ via {\em anticausal} solution of the system 
\begin{eqnarray}
\label{eqn:awebdrytr}
\frac{\partial {\tilde p}^{\pm}}{\partial t} & = & - \kappa \nabla \cdot {\tilde \bv}^{\pm} \mbox{ in } \pm(z-z_r) > 0, \nonumber \\
\frac{\partial {\tilde \bv}^{\pm}}{\partial t} & = & - \beta \nabla {\tilde p}^{\pm} \mbox{ in } \pm(z-z_r) > 0,\nonumber \\
{\tilde p}^{\pm} & =& 0 \mbox{ for } t \gg 0\nonumber\\ 
{\tilde \bv}^{\pm} & = & 0 \mbox{ for } t \gg 0 \nonumber\\
\lim_{z\rightarrow z_r^{\pm}}{\tilde p} & = & {\tilde d}_r 
\end{eqnarray}
%\end{thm}
 for the receiver surface $z=z_r$ (in the math literature, this is the ``Dirichlet-to-Neumann operator'', more or less). The discussion so far can be summarized as follows:
\begin{equation}
\label{eqn:wadj}
\bar{p}|_{z=z_s} = S[c]_{s,r}^T\Lambda[c]_r \bar{p}|_{z=z_r} 
\end{equation}
According to the discussion above, $\bar{p}|_{z=z_s} \approx p|_{z=z_s}$, and $h_s = \Lambda[c]_s p|_{z=z_s} = S[c]_{s,r}^{\dagger}d_r$. That is,
\begin{equation}
\label{eqn:appinv}
S[c]_{s,r}^{\dagger} = \Lambda[c]_s S[c]_{s,r}^T \Lambda[c]_r
\end{equation}
This relation can be re-written in the useful form
\begin{equation}
\label{eqn:adj}
S[c]_{s,r}^{\dagger} = W_m[c]^{-1}S[c]_{s,r}^TW_d[c]
\end{equation}
in which 
\begin{equation}
\label{eqn:weights}
W_m[c] = \Lambda[c]_s^{-1}\,\, W[c]_d = \Lambda[c]_r
\end{equation}
Since $\Lambda[c]$ is positive (semi-)definite, equation \ref{eqn:adj} exhibits $S[c]_{s,r}^{\dagger}$ as the adjoint of $S[c]_{s,r}$ with respect to weighted norms 
\begin{itemize}
\item on the source space ($h_s$): weight $W[c]_m$
\item on the data space ($d_r$): weight $W[c]_d$
\end{itemize}
Since $S[c]_{s,r}^{\dagger}S[c]_{s,r} \approx I$ as shown above, $S[c]_{s,r}$ is approximately unitary in the Hilbert spaces of source and data traces with norms defined by the weighting operators $W_m$ and $W_d$ respectively. Therefore a Krylov space method employing these norms will converge rapidly.

\cite{HouSymes:EAGE16} demonstrated a very similar preconditioner for Least Squares Migration, also for its subsurface offset extension \cite[]{HouSymes:16}, motivated by \cite{tenKroode:12}. These constructions all involve the Dirichlet-to-Neumann operator. This concept also turns up in hidden form in the work of Yu Zhang and collaborators on true amplitude migration \cite[]{YuZhang:14,TangXuZhang:13,XuWang:2012,XuZhangTang:11,Zhang:SEG09,ZhangYuSun:08,ZhangSunGray:07,ZhangBleistein:05,Bleisteinetal:05}.
 
\subsection{Implementation Considerations}
The Dirichlet-to-Neumann operator $\Lambda$ is an essential part of the inner problem preconditioner just presented. Implementation can be accomplished in several ways:
\begin{itemize}
\item \cite{tenKroode:12} suggests using a one-way operator;
\item if both pressure and normal partical velocity are measured (or simulated), then the two are related by $\Lambda$ and the velocity component can simply be used as the output;
\item presence of a free surface implies all of the usual problems, such as the need for removal of receiver-side ghosts. On the other hand, if the free surface is within a quarter-wavelength throughout the useful bandwidth of the data, then the ghosted data differs from $\Lambda p$ by a time integration and a scale factor, a fact used to good effect by \cite{HouSymes:15}.
\end{itemize}

In the examples, I have used the second observation. With a finite difference implementation of the pressure-velocity system \ref{eqn:awe}, velocity components are available ``for free'', short-circuiting explicit computation of $\Lambda$.

The variable projection gradient formula \ref{eqn:l2grad} has an Achilles heel, not mentioned so far: it is correct only when the normal equation \ref{eqn:normal} is satisfied {\em exactly}. Any iterative method (or the asymptotic inverse developed in the last subsection) solves \ref{eqn:normal} only approximately, so a nonzero error term is neglected in using \ref{eqn:l2grad}. This error term can be large, because it amplifies the high frequencies in the solution error, in fact depends on derivatives of the solution. For pure transmission through transparent (smooth) material models, the approximate inverse $S[c]_{s,r}^{\dagger}$ is asymptotically exact (at least in principle), and that fact can be used to devise a modification of \ref{eqn:l2grad} that converges with a convergent iteration for \ref{eqn:normal}. [LAST YEAR TRIP REPORT, MAY PUT SOMETHING IN APPENDIX]

Choice of the penalty weight $\alpha$, and of region in which the extended source $g$ is permitted to be nonzero, must be managed. These two choices are linked. Lei Fu's thesis \cite[]{Fu:Geo17,Fu:Geo17b} explains and tests algorithms for similar choices that occur in subsurface offset WEMVA. All of these ideas apply {\em ipso facto} to the surface source extension.

\subsection{Practical Preconditioning}

The formula \ref{eqn:adj} allows direct use of the conjugate gradient (or other Krylov space iterative) algorithm with the inner products described above. This is however computationally inconvenient, as it requires explicit computation of the weight operators, in this case the Dirichlet-to-Neumann operator. There are several ways to carry out this computation, as mentioned somewhere, but it is in any case a  pain. On the other hand, it is possible to rearrange the calculation with weighted norms into the form of the {\em preconditioned conjugate gradient (PCG) algorithm}. For the current problem, identify $A=S[c]_{s,r}$, $A^* = S[c]_{s,r}^T W_d$. PCG takes the form
\begin{algorithm}[H]
\caption{Preconditioned Conjugate Gradient Algorithm}
\begin{algorithmic}[1]
\State Choose $x_0$ somehow
  \State $r_0 \gets A^*(b-Ax_0)$
  \State $p_0 \gets W_m^{-1}r_0$
  \State $g_0 \gets p_0$
  \State $q_0 \gets A^*Ap_0$
  \State $k \gets 0$
  \Repeat
  \State $\alpha_k \gets \frac{\langle g_k,r_k \rangle}{\langle p_k,q_k\rangle}$
  \State $x_{k+1} \gets x_k + \alpha_k p_k$
  \State $r_{k+1} \gets r_k - \alpha_kq_k$
  \State $g_{k+1} \gets W_m^{-1}r_{k+1}$
  \State $\beta_{k+1} \gets \frac{\langle g_{k+1},r_{k+1}\rangle}{\langle g_k,r_k\rangle}$
  \State $p_{k+1}\gets g_{k+1}+\beta_{k+1}p_k$
  \State $q_{k+1} \gets A^*Ap_{k+1}$
  \State $k \gets k+1$
  \Until{Error is sufficiently small, or max iteration count exceeded} 
\end{algorithmic}
\end{algorithm}
Of course, this variant of CG merely hides the data sides weight operator, and requires application on the model side. This is still inconvenient. 

The simplest solution is to use the coexistence of the $d_r=p$ and $\Lambda[c]_rd_r =[v_z]=2v_z$ traces (assuming a horizontal datum), and similarly for the source datum. That is, the computation of $\Lambda[c]_r$ is intrinsic: when $S[c]_{s,r}h_s$ has been computed, so has $\Lambda[c]_rS[c]h_s$ - it is simply the collection of corresponding vertical velocity traces. Similarly,  $\Lambda[c]_sS[c]^T$ is the collection of vertical velocity traces at $z=z_s$ arising from the time-reversal computation input equal to sources traces on $z=z_r$. If we can rewrite the PCG loop to require only these computations, then the acoustic simulations in forward and reverse time will suffice to compute the step.

In the loop body above, introduce the vector sequences $t_k=Ap_k,v_k=W_d t_k, s_k=W_m^{-1}q_k$, and re-write the iteration by unfolding $W_m^{-1}S[c]^T W_d S[c]$ and noting that $\langle p_k, q_k \rangle =\langle p_k,A^TW_dAp_k \rangle =\langle Ap_k,W_dAp_k \rangle =\langle t_k,v_k\rangle$: 
\begin{algorithm}[H]
\caption{Modified Preconditioned Conjugate Gradient Algorithm}
\begin{algorithmic}[1]
\State Choose $x_0$ somehow
  \State $r_0 \gets A^*(b-Ax_0)$
  \State $p_0 \gets W_m^{-1}r_0$
  \State $g_0 \gets p_0$
  \State $k \gets 0$
  \Repeat
  \State $t_k \gets Ap_k$
  \State $v_k \gets W_dt_k$
  \State $q_k \gets A^Tv_k$
  \State $s_k \gets W_m^{-1}q_k$
  \State $\alpha_k \gets \frac{\langle g_k,r_k \rangle}{\langle t_k,v_k\rangle}$
  \State $x_{k+1} \gets x_k + \alpha_k p_k$
  \State $r_{k+1} \gets r_k - \alpha_kq_k$
  \State $g_{k+1} \gets g_k - \alpha_k s_k$
  \State $\beta_{k+1} \gets \frac{\langle g_{k+1},r_{k+1}\rangle}{\langle g_k,r_k\rangle}$
  \State $p_{k+1}\gets g_{k+1}+\beta_{k+1}p_k$
  \State $k \gets k+1$
  \Until{Error is sufficiently small, or max iteration count exceeded} 
\end{algorithmic}
\end{algorithm}
This rewrite does not look like an improvement - four operator applications appear to be required:
\begin{itemize}
\item $p_k \rightarrow S[c] p_k = t_k$
\item $p_k \rightarrow  \Lambda[c]_r S[c] p_k = v_k$
\item $v_k \rightarrow S[c]^Tv_k = q_k$
\item $v_k \rightarrow \Lambda[c]_s S[c]^T v_k = s_k$
\end{itemize}
However this rearrangement reveals that actually only two wave equation solves are needed. For $q_k$ and $s_k$, both by-products of the adjoint (time-reversed) simulation: $q_k$ stores the pressure traces on $z=z_s$, $s_k$ the velocity traces. The same is true of $t_k$ and $v_k$, with the latter being the input for the $q_k,s_k$ computation.

Denote by $F_{pp}$ the acoustic simulation operator with a $p$ source (constitutive law defect, as in the system \ref{eqn:awedata}), and $p$ output traces. Similarly, denote by $F_{pv}$ the simulation operator with $p$ source and $v_z$ output traces, likewise $F_{vp}$ and $F_{vv}$, and by ${\bf F}$ the matrix operator
\begin{equation}
\label{eqn:iwop}
{\bf F} = \left(
\begin{array}{cc}
F_{pp} & F_{vp} \\
F_{pv} & F_{vv}
\end{array}
\right)
\end{equation}
The {\tt IWaveLOVOp} built in the asg package implements this matrix operator if the keywords {\tt source\_p, source\_v0, data\_p, data\_v0} are defined in its parameter list: these keywords point to SEGY trace files that define the spaces in which the $p$ and $v_z$ sources respectively data traces are treated as vectors. That is, IWAVE provides an easy access to ${\bf F}$. In terms of the operators used in the statement of the inverse problem, $F_{pp}=S[c]$, $F_{pv}=\Lambda[c]_rS[c]$, $F_{vp} = S[c]\Lambda[c]_s$, $F_{pp}^T = S[c]^T$, and $F_{vp}^T = \Lambda[c]_sS[c]^T$. So if we define 
\begin{equation}
\label{eqn:vecvec}
{\bf p}_k = \left[
\begin{array}{c}
p_k\\
0
\end{array}
\right],\,\,
{\bf r}_k = \left[
\begin{array}{c}
r_k\\
g_k
\end{array}
\right],\,\,
{\bf t}_k = \left[
\begin{array}{c}
t_k\\
v_k
\end{array}
\right],\,\,
{\bf v}_k = \left[
\begin{array}{c}
v_k\\
0
\end{array}
\right],\,\,
{\bf q}_k = \left[
\begin{array}{c}
q_k\\
s_k
\end{array}
\right],
\end{equation}
and
\begin{equation}
\label{eqn:proj}
{\bf P} = \left(
\begin{array}{cc}
0 & I \\
0 & 0
\end{array}
\right),
\end{equation}
then the algorithm listing above can be rewritten as
\begin{algorithm}[H]
\caption{Further modified Preconditioned Conjugate Gradient Algorithm}
\begin{algorithmic}[1]
\State Choose $x_0$ somehow
  \State $r_0 \gets A^TW_d(b-Ax_0)$
  \State $p_0 \gets W_mr_0$
  \State $g_0 \gets p_0$
  \State $k \gets 0$
  \Repeat
  \State ${\bf t}_k \gets {\bf F}{\bf p}_k$
  \State ${\bf v}_k \gets {\bf P}{\bf t}_k$
  \State ${\bf q}_k \gets {\bf F}^T{\bf v}_k$
  \State $\alpha_k \gets \frac{\langle g_k,r_k \rangle}{\langle t_k,v_k\rangle}$
  \State $x_{k+1} \gets x_k + \alpha_k p_k$
  \State ${\bf r}_{k+1} \gets {\bf r}_k - \alpha_k{\bf q}_k$
  \State $\beta_{k+1} \gets \frac{\langle g_{k+1},r_{k+1}\rangle}{\langle g_k,r_k\rangle}$
  \State ${\bf p}_{k+1}\gets {\bf P}{\bf r}_{k+1}+\beta_{k+1}{\bf p}_k$
  \State $k \gets k+1$
  \Until{Error is sufficiently small, or max iteration count exceeded} 
\end{algorithmic}
\end{algorithm}

Note that
\begin{equation}
\label{eqn:note}
{\bf r}_0 = \left[
\begin{array}{c}
r_0\\
g_0 
\end{array}
\right] = 
\left[
\begin{array}{c}
r_0\\
p_0 
\end{array}
\right] = 
\left[
\begin{array}{c}
A^TW_d(b-Ax_0)\\
W_m^{-1}A^TW_d(b-Ax_0)
\end{array}
\right]
\end{equation}
Define 
\begin{equation}
\label{eqn:rhsdef}
{\bf b}
= 
\left[
\begin{array}{c}
W_d(b-Ax_0)\\
0
\end{array}
\right].
\end{equation}
Then identity \ref{eqn:note} implies that
\begin{equation}
\label{eqn:init}
{\bf r}_0= {\bf F}^T{\bf b},\,\, {\bf p}_0 = {\bf P}{\bf r}_0.
\end{equation}
This observation allows a convenient ``hoist'' of the $k=0$ operator applications out of the iteration loop. Also, it is convenient to introduce the indefinite quadratic form that returns the inner product of the two components of a vector in the product space introduced above:
\begin{equation}
\label{eqn:dotfunc}
Q({\bf x})=\langle x_0,x_1\rangle=\left\langle \bx,
\left(
\begin{array}{cc}
0 & I \\
I & 0 
\end{array}
\right) \bx \right\rangle
\end{equation}
and the scalar sequences
\begin{eqnarray}
\label{eqn:scalars}
\gamma_k &=& \langle r_k,g_k \rangle = Q({\bf r})\\
\delta_k &=& \langle t_k,v_k \rangle = Q({\bf t})
\end{eqnarray}

With these modifications, we obtain 
\begin{algorithm}[H]
\caption{Intrinsically Preconditioned Conjugate Gradient Algorithm}
\begin{algorithmic}[1]
\State Choose $x_0$ somehow
\State ${\bf b} \gets \left[
\begin{array}{c}
W_d(b-Ax_0)\\
0
\end{array}
\right]$
  \State ${\bf r}_0 \gets {\bf F}^T{\bf b}$
  \State ${\bf p}_0 \gets {\bf P}{\bf r}_0$
  \State $\gamma_0 \gets Q({\bf r}_0)$
  \State $k \gets 0$
  \Repeat
  \State ${\bf t}_k \gets {\bf F}{\bf p}_k$
  \State $\delta_k \gets Q({\bf t})$
  \State ${\bf v}_k \gets {\bf P}{\bf t}_k$
  \State ${\bf q}_k \gets {\bf F}^T{\bf v}_k$
  \State $\alpha_k \gets \frac{\gamma_k}{\delta_k}$
  \State $x_{k+1} \gets x_k + \alpha_k p_k$
  \State ${\bf r}_{k+1} \gets {\bf r}_k - \alpha_k{\bf q}_k$
  \State $\gamma_{k+1} \gets Q({\bf r}_{k+1})$
  \State $\beta_{k+1} \gets \frac{\gamma_{k+1}}{\gamma_k}$
  \State ${\bf p}_{k+1}\gets {\bf P}{\bf r}_{k+1}+\beta_{k+1}{\bf p}_k$
  \State $k \gets k+1$
  \Until{Error is sufficiently small, or max iteration count exceeded} 
\end{algorithmic}
\end{algorithm}


\section{Prototype Numerical Examples}
\inputdir{project}

I present a collection of simple examples that illustrate the features of the surface source extension claimed in preceding sections. 

I used the IWAVE acoustic staggered grid package to carry out these calculations. This package implements (2,2k) schemes for k=1,2,..., and outputs traces (of either velocity or pressure at any point in space via multilinear interpolation. The discretized modeling operator is thus of second order accuracy, though as usual I have used higher order in space to reduce grid dispersion.

Source injection is implemented as the adjoint of trace sampling, resulting in another second-order error [REFERENCES]. 

The data is a single shot gather, with a source at coordinates $x_s=z_s=3000$ m (units of length are meters in all cases). The receiver line occupies $1500 \le x_r \le 5500$ m, with receiver depth $z_r=1000$ m.  Extended sources occupy $1500 \le x_s \le 5500$ m, with the same depth $z_s=3000$ m as the ``physical'' source used to generate the data. This region turns out to be adequate to represent the extended sources that approximately invert the data, for the cases examined below. An algorithm to automatically identify an appropriate region can be based on the ideas developed by \cite{Fu:Geo17}.

I have used absorbing boundary conditions (split-field PML) on all four sides of the 4000 m (vertical) $\times$ 8000 m (horizontal) simulation domain. Evidently includion of a free surface is important to the application of the ideas explained here to diving wave marine data, and I have not addressed the necessary modifications here. 

The script is set up to carry out the necessary computations on grids with spacings $\Delta x = \Delta z = $ 20, 10, and 5 m, with a jump of roughly 8 in computation time resulting from each refinement. For present purposes, the coarsest (20 m) grid seems to be sufficient, and that is the grid used in the examples presented below. The source pulses are chosen so that the computation is reasonably accurate. For the 20 m grid case, I use a zero-phase trapezoidal bandpass filter source with corner frequencies of 1.0, 2.0, 7.5, and 12.5 Hz.

The IWAVE asg driver has been set up to recognize the case {\tt deriv=0} as defining the map from source (right-hand side in the pressure equation) to data (pressure) traces. The adjoint to this map, as explained above, is reverse-time propagation of the data traces as pressure sources, followed by scaling (formula \ref{eqn:sadj}). The approximate inverse is computed by application of the Dirichlet-to-Neumann operator to the pressure traces to produce corresponding velocity traces, followed by injection as pressure sources and reverse time propagation, followed by another application of the Dirichlet-to-Neumann map and scaling (formulas \ref{eqn:appinv}, \ref{eqn:adj}).

The script for the first set of examples implements these operatations step-by-step via calls to IWAVE, Madagascar, and SU commands. A peculiarity of the {\tt asg.x} driver needs to be mentioned: it is based on an un-scaled version of the constitutive law defect source representation, that is, {\tt asg.x} approximately computes the solution of the system \ref{eqn:awedata} with the first equation replaced by
\begin{equation}
\label{eqn:asgdata}
\frac{\partial p}{\partial t}  =  - \kappa \nabla \cdot \bv +
h \delta(z-z_s).
\end{equation}
Denote by $S_{\rm asg}[c]$ the forward map produced by {\tt asg.x}. Then comparison of \ref{eqn:awedata} and \ref{eqn:asgdata} reveals that
\begin{equation}
\label{eqn:sreln}
S[c]=S_{\rm asg}[c]\kappa
\end{equation}
where $\kappa$ is shorthand for the operator of multiplication by $\kappa$. Accordingly, and approximate inverse for $S_{\rm asg}[c]$ is
\[
I \approx S_{\rm asg}[c]^{\dagger}S_{\rm asg}[c] = S_{\rm asg}[c]^{\dagger}S[c]\kappa^{-1}
\]
Since $S[c]S[c]^{\dagger} \approx I \approx S[c]^{\dagger}S[c]$, it follows that
\[
S_{\rm asg}[c]^{\dagger}=\kappa S[c]^{\dagger} = \kappa\Lambda[c]_s S[c]^T \Lambda[c]_r 
\]
\begin{equation}
\label{eqn:asginv}
= \kappa \Lambda[c]_s \kappa S_{\rm asg}[c]^T\Lambda[c]_r
\end{equation}
This is the approximate inverse computed in the examples. Note that only the values of $\kappa$ near the source datum $z=z_s$ play a role in the relation \ref{eqn:sreln} or in the definition \ref{eqn:asginv} of the IWAVE ASG approximate inverse.

These examples are based on two different material models. The first is a homogeneous model, with $\kappa=4.0$ GPa and $\rho=1.0$ g/cm$^{3}$. Figure \ref{fig:ptpwindh0} shows the shot gather computed in the configuration descritbed above for this choice of propagation medium. As mentioned in the preceding section, the velocity traces can be recorded in the same IWAVE workflow: these are displayed in 
\ref{fig:ptvzwindh0}. 

The first group of plots show pressure traces for source position $z_s=3$ km, $x_s=3$ km, 201 receivers at $z_r=1$ km, $2 \le x_r \le 6$ km. 

\plot{ptpwindh0}{width=15cm}{Receiver line at $z_r=1$ km for source at $z_s=3$ km, $x_s=3$ km. Homogeneous material model, $\kappa=4$ GPa, $\rho$=1 g/cm$^{3}$. Coarse grid: $dx=dz=20$ m, $dt=$ 8 ms, (2,4) staggered grid scheme. }
\plot{ptvzwindhh0}{width=15cm}{$v_z$ traces corresponding to the pressure traces of Figure \ref{fig:ptpwindh0}.}
\plot{srcvzghh0}{width=15cm}{Source reconstructed from $v_z$ traces in Figure \ref{fig:ptvzwindhh0} by time reversal (approximate inverse) algorithm explained in text.}
\plot{reptpwindhh0}{width=15cm}{Resimulated pressure data from reconstructed source if Figure \ref{fig:srcvzghh0}.} 
\plot{trcftrhh0}{width=15cm}{Middle trace from pressure, resimulated pressure traces in Figures \ref{fig:ptpwindh0}, \ref{fig:reptpwindhh0}.}.

\plot{bml0}{width=15cm}{Inhomogenous bulk modulus field, with low velocity lens.}
\plot{ptpwindl0}{width=15cm}{Receiver line at $z_r=1$ km for source at $z_s=3$ km, $x_s=3$ km. bulk modulus with low velocity lens as in Figure \ref{fig:bml0}, $\rho$=1 g/cm$^{3}$. Coarse grid: $dx=dz=20$ m, $dt=$ 8 ms, (2,4) staggered grid scheme. }
\plot{ptvzwindll0}{width=15cm}{$v_z$ traces corresponding to the pressure traces of Figure \ref{fig:ptpwindl0}.}

\plot{srcvzglh0}{width=15cm}{Source reconstructed from $v_z$ traces in Figure \ref{fig:ptvzwindll0} by time reversal (approximate inverse) algorithm explained in text, propagation in homogeneous material model (that is, ``wrong velocity'').}
\plot{reptpwindlh0}{width=15cm}{Resimulated pressure data from reconstructed source if Figure \ref{fig:srcvzglh0}, both approximate inversion and re-simulation in  homogeneous material model (``wrong velocity'').} 
\plot{trcftrlh0}{width=15cm}{Middle trace from pressure, resimulated pressure traces in Figures \ref{fig:ptpwindl0}, \ref{fig:reptpwindlh0}.}

\plot{srcvzgll0}{width=15cm}{Source reconstructed from $v_z$ traces in Figure \ref{fig:ptvzwindll0} by time reversal (approximate inverse) algorithm explained in text, propagation in bulk modulus of Figure \ref{fig:bml0} (that is, ``correct velocity'').}
\plot{reptpwindll0}{width=15cm}{Resimulated pressure data from reconstructed source if Figure \ref{fig:srcvzgll0}, both approximate inversion and re-simulation in bulk modulus of Figure \ref{fig:bml0} (``correct velocity'').} 
\plot{trcftrll0}{width=15cm}{Middle trace from pressure, resimulated pressure traces in Figures \ref{fig:ptpwindl0}, \ref{fig:reptpwindll0}.}


