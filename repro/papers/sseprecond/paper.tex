\title{Efficient Computation of Extended Sources}
\author{William. W. Symes \thanks{The Rice Inversion Project,
Department of Computational and Applied Mathematics, Rice University,
Houston TX 77251-1892 USA, email {\tt symes@caam.rice.edu}.}}

\lefthead{Symes}

\righthead{Approximate Source Inversion}

\maketitle
\begin{abstract}
Source extension is a reformulation of inverse problems in wave propagation, that at least in some cases leads to computationally tractable iterative solution methods. The core subproblem in all source extension methods is the solution of a linear inverse problem for a source (right hand side in a system of wave equations) through minimization of data error in the least squares sense with soft imposition of physical constraints on the source via an additive quadratic penalty. A variant of the time reversal method from photoacoustic tomography provides an approximate solution that can be used to precondition Krylov space iteration for rapid convergence to the solution of this subproblem. An acoustic 2D example for sources supported on a surface, with a soft contraint enforcing point support, illustrates the effectiveness of this preconditioner.
\end{abstract}

\section{Introduction}
Full Waveform Inversion (FWI) can be described in terms of 
\begin{enumerate}
\item a linear wave operator $L[\bf{c}]$, depending on an array of space-dependent coefficients $\bf{c}$ and acting on wavefields $\bu$ vanishing in negative time:
\begin{equation}
\label{eqn:init}
\bu \equiv 0, t \ll 0; 
\end{equation}
\item a trace sampling operator $P$ acting on wavefields and producing data traces;
\item and a source function (of space and time) $\bff$ representing energy input to the system. 
\end{enumerate}
The basic FWI problem is: given data $d$, find $\bf{c}$ so that 
\begin{equation}
\label{eqn:fwi}
P\bu \approx d \mbox{ and } L[\bf{c}]\bu = \bff.
\end{equation}

The energy source $\bff$ may also be largely undetermined, apart from some known characteristics such as localization in space and/or time. In fact, additional source degrees of freedom, beyond those needed to describe physically realized sources, may be useful in rendering the FWI problem \ref{eqn:fwi} more amenable to numerical solution, via so-called extended modeling (see \cite{geoprosp:2008}, \cite{LeeuwenHerrmannWRI:13}, \cite{HuangNammourSymesDollizal:SEG19}, and many references cited there). Therefore it is natural to view $\bff$ as also an unknown in formulating the problem \ref{eqn:fwi} via nonlinear least squares:
%A typical nonlinear least squares formulation is:
%\begin{equation}
%\label{eqn:ols}
%\mbox{choose } c \mbox{ to minimize } \|PL[c]^{-1}f -d \|^2.
%\end{equation}

%As is well-known, local optimization methods are the only feasible approach given the dimensions of a typical instance of \ref{eqn:fwi}, and those have a tendency to stall due to ``cycle-skipping''. Source extension is one approach to avoiding this problem. It consists in imposing the wave equation as a soft as opposed to hard constraint, by allowing the source to have more degrees of freedom than is permitted by a faithful  model model of the seismic experiment, and constraining these additional degrees of freedom by means of an additive penalty modifying the probem \ref{eqn:ols}:
\begin{equation}
\label{eqn:esi}
\mbox{choose } \bf{c}, \bff \mbox{ to minimize } \|PL[\bf{c}]^{-1}\bff -d \|^2 + \alpha^2 \|A\bff\|^2 
\end{equation}
The operator $A$ penalizes deviation from known (or assumed) characteristics of the source function - its null space consists of feasible source models. 

This paper presents a numerically efficient approach to solving the {\em source subproblem}
\begin{equation}
\label{eqn:esis}
\mbox{given } \bf{c}, \mbox{ choose } \bff \mbox{ to minimize } \|PL[\bf{c}]^{-1}\bff -d \|^2 + \alpha \|A\bff\|^2 
\end{equation}

The penalty operator $A$ is assumed linear in this work, so the source subproblem is a linear least squares problem. Under some additional assumptions to be described below, I shall show how to construct an accurate approximate solution operator for problem \ref{eqn:esis}. This approximate solution operator may be used to accelerate Krylov space methods for the solution of the source subproblem \ref{eqn:esis}. Numerical examples suggest the effectiveness of this acceleration.

The source subproblem is a necessary step in solving the overall FWI problem \ref{eqn:fwi}. In particular, the nonlinear least squares realization \ref{eqn:esi} of source-extended FWI is naturally approached via the {\em variable projection method} \cite[]{GolubPereyra:73,GolubPereyra:03,vanLeeuwenMulder:09,Rickett:SEG12}, in which the minimum over $\bff$ in \ref{eqn:esis} is treated as a function of $\bf{c}$, which is in turn minimized. Variable projection thus treats the source subproblem as an inner problem, which must be solved for an estimate of $\bff$ at every step of an iterative method for the outer problem of minimization over $\bf{c}$. Efficiency in solving the source subproblem \ref{eqn:esis} is critical to efficient implementation of variable projection for solving the regularized FWI problem \ref{eqn:esi}.

This paper restricts the choice of wave physics embodied in
$L[\bf{c}]$ to linear acoustics.  Thus $\bf{c}=(\kappa,\rho)$ is the
pair (bulk modulus, density) of positive functions of spatial
position. The principal characteristics assumed of sources $\bff=$ are localization and isotropy. That is, physical sources will be assumed to be isotropic point radiators, described by the functional form
\begin{equation}
\label{eqn:ptsrc}
f_{\rm pt}(\bx,t;\bx_s) = w(t)\delta(\bx-\bx_s). 
\end{equation}
Source locations $\bx_s$ are assumed known (as is natural for active source methods), and the source {\em wavelet} $w(t)$ is to be found as part of the solution of \ref{eqn:esi}. A convenient choice of penalty operator $A$ is then multiplication by the {\em offset} $|\bx-\bx_s|$: its null space consists precisely of distributions of the form \ref{eqn:ptsrc}. 

More complex radiation characteristics may be accommodated with similar but more complex choice for the operator $A$. Since the core analysis is similar, this paper deals only with the simplest case \ref{eqn:ptsrc}.

The wavefield $u$ in this work is presumed to exist in all of Euclicean space-time: in other words, boundary effects have been removed from $u$, by surface-related multiple elimination or other techniques. Predicted data traces are simply the samples of one or more components of $u$ at receiver points $\bx_r$.

%The domain of wave propagation is denoted $\Omega$, and two subsets of its boundary are identified: $\Gamma_s$ contains the support (non-zeroes) of the (extended) sources and in particular the locations $\bx_s$ of physical sources. Data trace locations $\bx_r$ lie in another subset $\Gamma_r$. The data projection operator $P$ samples the acoustic field $u$ on $\Gamma_r$, and includes a finite aperture mute.  

Achieving a small residual in the source subproblem \ref{eqn:esis} for arbitrary $c$ is a critical part of the convergence mechanism for the extended source approach to FWI \cite[]{HuangNammourSymesDollizal:SEG19}. However, for arbitrary data $d$, coefficient array $c$, and source location $\bx_s$, there does not exist an isotropic point source $f_{\rm pt}$ of the form \ref{eqn:ptsrc} for which $PL[c]^{-1}f_{\rm pt} \approx d$. This is so even if there does exist a coefficient array $c^*$ and point source $f_{\rm pt}^*$ located at $\bx_s$ with wavelet $w^*(t)$ for which $d = PL[c^*]^{-1}f_{\rm pt}^*$, if $c$ differs substantially from $c^*$. It is this fact that underlies the effectiveness of the extended source approach to FWI:  driving the residual in the problem \ref{eqn:esi} towards zero necessarily requires modifying $c$ to resemble $c^*$, assuming the latter exists, as well as pushing the optimal $f$ towards the null space of $A$. Conversely, the source subproblem \ref{eqn:esis} does not have a small residual solution of point source form \ref{eqn:ptsrc}, in general, for a given choice of $c$, even if that were the case for a different choice ($c^*$). Therefore a more general class of source models than that specified by the condition \ref{eqn:ptsrc} must be admitted to the feasible set for the source subproblem \ref{eqn:esis} if it is to serve as the inner problem in a variable projection formulation of extended source FWI.

The class of non-point sources investigated here are those confined a hypersurface assumed to contain the locations of physical (point) sources, but not {\em a priori} required to have point support. These {\em surface extended sources} are able to yield a relatively small residual in the source subproblem \ref{eqn:esis} for more or less arbitrary coefficient array $c$. This observation is a by-product of the approximate solution for \ref{eqn:esis} constructed below. The construction of the approximate solution is closely related to the {\em time reversal} method of photoacoustic tomography (see \cite{StefanovUhlmannIP:09} and references cited there).

The next section gives a precise description of an acoustic version of problem \ref{eqn:esis} for an idealized {\em crosswell} configuration, in which source located on a surface $z=z_s$ generate waves that propagate to to a receiver surface $z=z_r > z_s$. In principle, {\em diving waves} can be described with similar mathematics, but with some additional complications, so I do not treat the diving wave case explicitly in this paper. The assumptions detailed here imply that the data $d$ of the inverse problems \ref{eqn:esi}, \ref{eqn:esis} have the physical character of {\em transmitted waves}. There are no mathematical results at present concerning reflected wave inverse problems treated by source extension methods, though there are tantalizing numerical clues \cite[]{LeeuwenHerrmannWRI:13,Warner:14,Warner:16,LeeuwenHerrmann:16,HuangSymes:Geo17,HuangSymes:Geo18a,HuangSymes:Geo18b}.

The following section describes the construction of the approximate
inverse and explains the conditions under which accuracy should be expected. I observe that the approximate inverse is approximately the adjoint of the modeling operator $PL[c]^{-1}$ with respect to weighted norms in its domain and range (see \cite{HouSymes:15} for a similar observation in a different context). This fact immediately suggests use of the approximate inverse as a preconditioner to accelerate convergence of Krylov space methods such as conjugate gradient iteration applied to the least squares problem \ref{eqn:esis}. However, its straightforward application in the preconditioned conjugate gradient (PCG) method \cite[]{Golub:2012} involves explicitly a version the so called Dirichlet-to-Neumann (D2N) operator, which is computationally awkward. I show how to reorganize the PCG iteration so that only solutions of $L[c]u=f$ are required. The penultimate section presents some 2D examples in the crosswell configuration, illustrating the accuracy of the approximate inversion and the accelerated convergence of PCG. The examples are chosen to emphasize that surface extended sources can be constructed to fit more or less arbitrary data, unlike point sources - as mentioned before, this approximate invertibility property of the modeling operator is of critical importance in the application to extended FWI. The paper ends with a discussion of several important matters not addressed here, and a restatement of the conclusions.

The intent of the main body of this paper is to present the formal structure of the extended source subproblem and the way in which this structure leads to accelerated numerical solution. This formal structure is however supported by a rigorous foundation. In order to avoid disrupting the formal account, this foundation material is relegated to an appendix.

\section{Surface Sources and Solutions}

For acoustic wave physics, the coefficient vector $c$ is the pair $\bf{c}=(\kappa,\rho)$ of bulk modulus $\kappa$ and density $\rho$, and the state vector $\bu=(p,\bv)^T$ consists of pressure $p$ (a scalar space-time field) and particle velocity $\bv$ (a vector space-time field). The wave operator $L[\bf{c}]$ is given by the linear acoustics system:
\begin{equation}
\label{eqn:aweop}
L[c]u = 
\left(
\begin{array}{c}
\frac{1}{\kappa}\frac{\partial p}{\partial t}  + \nabla \cdot \bv, \\
\rho\frac{\partial \bv}{\partial t} + \nabla p.
\end{array}
\right) 
\end{equation}
That is,
\begin{equation}
  \label{eqn:awemat}
  L[c] = \left(
    \begin{array}{cc}
      \frac{1}{\kappa}\frac{\partial}{\partial t} & \nabla \cdot \\
      \nabla & \rho \frac{\partial}{\partial t}
    \end{array}
  \right)
\end{equation}

Most of what follows is valid for any space dimension $n >0$. Examples
later in this paper will use $n=2$ for computationally convenience. In
the mathematical development that follows, I will set $n=3$.

As mentioned earlier, in this paper the coefficients $\bf{c}$ is regarded as defined throughout space $\bR^d$, the state vector $\bu$ throughout space-time $\bR^{d+1}$.

The idealized ``crosswell'' configuration involves sources confined to
$z=z_s$. Such sources are combinations of constitutive law defects and
loads normal to the surface, that is, right-hand sides in the system
$L[c]\bf{u}=\bf{f}$ of the form $\bf{f}(\bx,t) =
(h_s(x,y,t)\delta(z-z_s), f_s(x,y,t)\bf{e}_z\delta(z-z_s))^T$ for scalar
defect $h_s$ and normal force $f_s$ and $\bf{e}_z=(0,0,1)^T$. With the choice $L[\bf{c}]$ given in \ref{eqn:aweop}, the causal wave system $L[\bf{c}]\bu^+=\bff$ takes the form
\begin{eqnarray}
\label{eqn:awep}
\frac{1}{\kappa}\frac{\partial p^{+}}{\partial t} & = & - \nabla \cdot \bv^{+} +
h_s \delta(z-z_s), \nonumber \\
\rho\frac{\partial \bv^{+}}{\partial t} & = & - \nabla p^{+} + f_s\bf{e}_z \delta(z-z_s),\nonumber \\
p^{+} & =& 0 \mbox{ for } t \ll 0,\nonumber\\ 
\bv^{+} & = & 0 \mbox{ for } t \ll 0.
\end{eqnarray}

Similarly, the anti-causal wave system $L[c]u^-=f$ takes the form
\begin{eqnarray}
 \label{eqn:awem}
\frac{1}{\kappa}\frac{\partial p^{-}}{\partial t} & = & - \nabla \cdot \bv^{-} +
h_s \delta(z-z_s), \nonumber \\
\rho \frac{\partial \bv^{-}}{\partial t} & = & - \nabla p^{-} + f_s\bf{e}_z \delta(z-z_s),\nonumber \\
p^{-} & =& 0 \mbox{ for } t \gg 0,\nonumber\\ 
\bv^{-} & = & 0 \mbox{ for } t \gg 0.
\end{eqnarray}

\section{Operators and Adjoints}
All of the operators discussed in this section depend on the
coefficient array $\bf{c}$, which I will suppress from the notation.
Denote by $P_s,P_r$ the trace (sampling) operators on $z=z_s$, $z=z_r$
respectively. The causal and anticausal modeling operators
${\cal S}^{+}_{z_s,z_r}$ and ${\cal S}^-_{z_s,z_r}$ are defined in
terms of the solutions $(p^{\pm},\bv^{\pm})$ of the systems
\ref{eqn:awep} and \ref{eqn:awem} by
\begin{eqnarray}
  {\cal S}^{+}_{z_s,z_r}(h_s,f_s) & = & (P_rp^+,P_r v_z^+)|_{z=z_r},
                                        \nonumber\\
  {\cal S}^{-}_{z_s,z_r}(h_s,f_s) & = & (P_rp^-,P_r v_z^-)|_{z=z_r}.
  \label{eqn:fwd}
\end{eqnarray}
The subscript signifies that sources are located on $z=z_s$, the
receivers on $z=z_r$. It is necessary to include this information in
the notation, as versions of ${\cal S}^{\pm}$ with sources and receivers in
several locations will be needed in the discussion below.

The adjoint of ${\cal S}^+_{z_s,z_r}$ can be computed by a variant of
the adjoint state method, in this case a by-product of the
conservation of energy. Suppose that $p^-,\bv^-$ solve \ref{eqn:awem}
with $(h_s,f_s\bf{e}_z)\delta(z-z_s)$ replaced by
$ (h_r,f_r\bf{e}_z) \delta(z-z_r)$. Then
\[
0 = 
\left(\int\, dx\,dy\,dz\, \frac{p^+ p^-}{\kappa} +  
\rho \bv^+ \cdot \bv^- \right)|_{t \rightarrow \infty}
-
\left(\int\, dx\,dy\,dz\, \frac{p^+ p^-}{\kappa} +  \rho \bv^+ \cdot \bv^- \right)|_{t \rightarrow -\infty}
\]
\[
= 
\int_{-\infty}^{\infty} \,dt\, \frac{d}{dt}\left(\int\, dx\,dy\,dz\, \frac{p^+ p^-}{\kappa} +  \rho \bv^+ \cdot \bv^- \right)
\]
\[
= 
\int_{-\infty}^{\infty} \,dt\, \left(\int\, dx\,dy\,dz\, \frac{1}{\kappa} \frac{\partial p^+}{\partial t} p^- +  p^+ \frac{1}{\kappa}\frac{\partial p^-}{\partial t} \right.
\]
\[
+
\left. \rho \frac{\partial \bv^+}{\partial t} \cdot \bv^- + \rho \bv^+ \cdot \frac{\partial \bv^-}{\partial t} \right)
\]
\[
= 
\int_{-\infty}^{\infty} \,dt\, \left(\int\, dx\,dy\,dz\, \left(- \nabla \cdot \bv^+ + 
 h_s \delta(z-z_s)\right) p^- + p^+ \left(- \nabla \cdot \bv^- + 
 h_r \delta(z-z_r)\right) \right.
\]
\[
+
\left.  (- \nabla p^++f_s\bf{e}_z) \cdot \bv^- + \bv^+ \cdot (-\nabla
  p^- + f_r \bf{e_z}) \right)
\]
\[
= 
\int_{-\infty}^{\infty}\,dt\, \left(\int\, dx\,dy\,dz\, \left(- \nabla \cdot \bv^+ + 
 h_s \delta(z-z_s)\right) p^- + p^+ \left(- \nabla \cdot \bv^- + 
 h_r \delta(z-z_r)\right) \right.
\]
\[
+
\left.  p^+ (\nabla \cdot \bv^-) + (\nabla \cdot \bv^+) p^- 
  +f_s \delta(z-z_s) v_z^- + v_z^+f_r \delta(z-z_r) \right)
\]
after integration by parts in the last two terms. Most of what is left cancels, leaving 
\[
0 = \int_{-\infty}^{\infty}\,dt\,dx\,dy\, (h_sP_sp^-+f_zP_sv_z^-) +
( h_rP_rp^++f_rP_rv_z^+) = \langle (h_s,f_s), {\cal S}^-(h_r,f_r) \rangle+ \langle (h_r,f_r), {\cal S}^+_{z_s,z_r}(h_s,f_s) \rangle
\]
whence
\begin{equation}
\label{eqn:sadj}
 ({\cal S}^+_{z_s,z_r})^T = -{\cal S}^{-}_{z_r,z_s}.
\end{equation}

The systems \ref{eqn:awep} and \ref{eqn:awem} differ only in the direction of time evolution (causal vs. anti-causal). Define $R$ to be the {\em time-reversal operator} on functions of space-time,
$Rf(\bx,t) = f(\bx,-t)$, and ${\cal R}$ to be the {\em acoustic field time-reversal operator} 
\begin{equation}
  \label{eqn:trdef}
  {\cal R} \left(
    \begin{array}{c}
      p\\
      \bv
    \end{array}
  \right) =
  \left(
    \begin{array}{c}
      Rp\\
      -R\bv
    \end{array}
  \right)
\end{equation}
Then ${\cal R}(p^-,\bv^-)$ solves \ref{eqn:awep} with
$(h_s\delta(z-z_s),f_s\bf{e_z}\delta(z-z_s))$ replaced by
$(-Rh_r\delta(z-z_r), Rf_r\bf{e_z}\delta(z-z_r))$. That is,
\begin{equation}
  \label{eqn:trsadj}
  {\cal R}{\cal S}^- = -{\cal S}^+_{z_r,z_s}{\cal R}
\end{equation}
Since $R^2 = I$ and ${\cal R}^2 = I$, the identities \ref{eqn:sadj} and \ref{eqn:trsadj} imply that
\begin{equation} 
  \label{eqn:trtr}
 ({\cal S}^+_{z_s,z_r})^T = {\cal R}{\cal S}_{z_r,z_s}^+{\cal R}=
 -{\cal S}^-_{z_r,z_s}.
\end{equation}

\section{Surface source-to-pressure operator}

A particular case of the relation \ref{eqn:trtr} is important in its own right, when $z_r=z_s$. Define surface source-to-pressure operator $\Lambda_{z_s}$ by
\begin{equation}
  \label{eqn:ntoddef}
  \Lambda^{\pm}_{z_s} = S^{\pm}_{z_s,z_s}.
\end{equation}
Then \ref{eqn:trtr} reads
\begin{equation}
  \label{eqn:ntodtr}
  (\Lambda^+_{z_s})^T = R\Lambda_{z_s}^+R = -\Lambda^-_{z_s}
\end{equation}
This operator is closely related to the operator mapping $\lim_{z\rightarrow z_s^{\pm}} \bv_z^+$ to $\lim_{z\rightarrow z_s^{\pm}}  p^+$, often called the {\em Neumann-to-Dirichlet} operator. The connection is explained below.

The quadratic form defined by $\Lambda^{\pm}_{z_s}$ has fundamental physical
significance. Define the total acoustic energy $E^{\pm}(t)$ of the field $(p^{\pm},\bv^{\pm})$, at time $t$ by
\begin{equation}
  \label{eqn:defae}
  E^{\pm}(t) = \frac{1}{2} \int \,d\bx \, \left(\frac{(p^{\pm})^2}{\kappa} + \rho |\bv^{\pm}|^2\right)
\end{equation}
Then for $t_{\min}<t_{\max}$,
\[
  E^{\pm}(t_{\rm max})-E^{\pm}(t_{\rm min}) = \int_{t_{\rm min}}^{t_{\rm max}} \frac{dE^{\pm}}{dt}
\]
\[
  = \int_{t_{\rm min}}^{t_{\rm max}} \int\,d\bx\, \left(p^{\pm} \frac{1}{\kappa}\frac{\partial p^{\pm}}{\partial t} + \bv^{\pm} \cdot \rho \frac{\partial \bv^{\pm}}{\partial t}\right)
\]
\[
  =\int_{t_{\rm min}}^{t_{\rm max}} \int\,d\bx\,\left(p^{\pm}(-\nabla \cdot \bv^{+} + h_s\delta(z-z_s)) + \bv^{\pm} \cdot \rho \frac{\partial \bv^{\pm}}{\partial t}\right)
\]
\[
=  \int_{t_{\rm min}}^{t_{\rm max}}\int\,d\bx\, \left(\left(\nabla p^{\pm}+\rho \frac{\partial \bv^{\pm}}{\partial t}\right) + p^{\pm}h_s\delta(z-z_s)\right)
\]
\begin{equation}
  \label{eqn:eident}
  =  \int_{t_{\rm min}}^{t_{\rm max}}\int\,dxdy h_s p^{\pm}|_{z=z_s} = \int_{t_{\min}}^{t_{\max}}\langle h_s(t), (\Lambda^{\pm}_{z_s} h_s)(t) \rangle_{L^2(\bR^2)}.
\end{equation}
That is, $\langle h_s(t), (\Lambda^{\pm}_{z_s} h_s)(t)
\rangle_{L^2(\bR^2)}$ is the rate of energy transfer from source to
the fluid at time $t$.

Assume that $h_s$ has compact support in time. Then $E^{\pm}
\rightarrow 0$ as $t \rightarrow \mp \infty$, and is eventually
constant as $t \rightarrow \pm \infty$. Then the energy identity
\ref{eqn:eident} implies that
\begin{equation}
  \label{eqn:etot}
  \pm \lim_{t \rightarrow \pm \infty} E^{\pm}(t) = \int \,dt\, \langle
  h_s(t), (\Lambda^{\pm}_{z_s} h_s)(t)\rangle_{L^2(\bR^2)} = \langle
  h_s,\Lambda^{\pm}_{z_s} h_s\rangle
\end{equation}
By virtue of identity \ref{eqn:ntodtr},
\[
  \lim_{t \rightarrow -\infty}E^{-}(t) =-\langle
  h_s,\Lambda^{-}_{z_s} h_s\rangle
\]
\[
  =  \langle  h_s,(\Lambda^{^+})^T_{z_s} h_s\rangle
\]
\[
  =  \langle  h_s,\Lambda^{^+}_{z_s} h_s\rangle
\]
so
\begin{equation}
  \label{eqn:surfenergy}
  = \lim_{t \rightarrow \infty}E^{+}(t)
\end{equation}
That is, the energy total energy transferred from the source to the
causal acoustic field as it evolves forward in time is the same as the
total energy transferred to the anti-causal acoustic field as it
evolves backwards in time.

Also onclude from identity \ref{eqn:etot} that the symmetric part of $\Lambda^+_{z_s}$ is positive semidefinite:
\begin{equation}
  \label{eqn:lamsd}
  \frac{1}{2}((\Lambda_{z_s}^+)^T + \Lambda^+_{z_s}) \ge 0.
\end{equation}

%Observe that the causal acoustic system \ref{eqn:awep} implies directly that
%\begin{equation}
%  \label{eqn:sourcevjump}
%  h_s= [v_z]|_{z=z_s}.
%\end{equation}

\section{Parametrix via Time Reversal}

Define $H$ to be the subspace $\{u \in (L^2(\bR^3))^4: \mbox{supp
}u\subset \{z<z_s\}\}$, by analogy with \cite{Lax:PDENotes},
p. 122. Note: must add microlocal $H^1$ constraint per
\cite[]{BaoSy:91b} so that trace operator is well-defined - postpone
this.

Given $u=(\bar{p}_0,\bar{\bv}_0) \in H$, extend in $t$ by solving the acoustic system
\begin{eqnarray}
\label{eqn:awe0}
  \frac{1}{\kappa}\frac{\partial p_0}{\partial t} & = & - \nabla \cdot \bv_0, \nonumber \\
  \rho\frac{\partial \bv_0}{\partial t} & = & - \nabla p_0,\nonumber \\
  p_0 & =& \bar{p}_0, t=0,\nonumber\\ 
  \bv_0 & = & \bar{\bv}_0, t=0,\nonumber\\
\end{eqnarray}
Note that $(p_0,\bv_0)=0$ near $t=0$ in the region $z>z_s$.

Denote by $P_s$, respectively $P_r$, the trace operator on $z=z_s$,
respectively $z=z_r$. Given $(p_0,\bv_0)$ as above, define
$(p_1,\bv_1)$ as the solution in $z \ne z_s$ of
\begin{eqnarray}
\label{eqn:awe1}
  \frac{1}{\kappa}\frac{\partial p_1}{\partial t} & = & - \nabla \cdot \bv_1, \nonumber \\
  \rho\frac{\partial \bv_1}{\partial t} & = & - \nabla p_1,\nonumber \\
  p_1 & =& 0,  \mbox{ for } 0,\nonumber\\ 
  \bv_1 & = & 0 \mbox{ for } 0,\nonumber\\
  P_sp_1 = P_sp_0. 
\end{eqnarray}
Extended to form a distribution on all of $\bR^4$, $(p_1,\bv_1)$ solve the
inhomogeneous system
\begin{eqnarray}
\label{eqn:awe1}
  \frac{1}{\kappa}\frac{\partial p_1}{\partial t} & = &
                                                        ((\Lambda^+_{z_s})^{-1}P_sp_0)\delta(z-z_s) - \nabla \cdot \bv_1, \nonumber \\
  \rho\frac{\partial \bv_1}{\partial t} & = & - \nabla p_1,\nonumber \\
  p_1 & =& 0,  \mbox{ for } t=0,\nonumber\\ 
  \bv_1 & = & 0 \mbox{ for } t=0.\nonumber\\
\end{eqnarray}
where
\begin{equation}
  \label{eqn:defhs}
  (\Lambda^+_{z_s})^{-1}P_sp_0 = P_s[(\bv_1)_z].
\end{equation}

Since $p_0$ also solves the acoustic system \ref{eqn:awe1} in $z>z_s$
and has the same data at $t=0, z>z_s$ and trace on $z=z_s$, standard
uniqueness theorem shows that $(p_1,\bv_1) = (p_0, \bv_0)$ in $z>z_s$.

Introduce the operator $T^+_{z_s,z_r}$ mapping pressure on $z=z_s$ to
pressure on $z=z_r$: that is, $T^{+}_{z_s,z_r}P_sp_0 = P_rp_0$. From
the previous observation, $T^{+}_{z_s,z_r}P_sp_0 = P_rp_1$, that is,
you can compute $T^{+}$ by solving the system defining $p_1$, with
data $P_sp_0$. From the definition of $S^{+}_{z_s,z_r}$, the definition
\ref{eqn:defhs}, and the boundary condition for $p_1$,
\begin{equation}
  \label{eqn:relnST}
  T^+_{z_s,z_r} = S^+_{z_s,z_r} (\Lambda^+_{z_s})^{-1}.
\end{equation}

Let $\epsilon>0$ satisfy
\begin{equation}
  \label{eqn:defeps}
  E[{\bf 1}_{\bR^2 \times (-\infty,z_r]}(p_0,\bv_0)](T) \le \epsilon E[(p_0,\bv_0)]
\end{equation}
Omit the time on the RHS because the energy of the full field is
time-invariant. Inequality \ref{eqn:defeps} states that at time
$t=T$, the energy in
the region $z<z_r$ is at most $\epsilon$ times the energy in all of
space. For small $\epsilon$, in other words, most of the
energy has left $z<z_r$, at least temporarily, at $t=T$. This
assertion is similar to the outgoing field condition in Lax-Phillips
scattering theory, but is time-local and approximate.

Define $p_2$ to be the solution in $z \le z_r$ of
\begin{eqnarray}
\label{eqn:awe2}
  \frac{1}{\kappa}\frac{\partial p_2}{\partial t} & = & - \nabla \cdot \bv_2, \nonumber \\
  \rho\frac{\partial \bv_2}{\partial t} & = & - \nabla p_2,\nonumber \\
  p_2 & =& 0,  \mbox{ for } t=T,\nonumber\\ 
  \bv_2 & = & 0 \mbox{ for } t=T,\nonumber\\
  P_rp_2 = P_rp_0. 
\end{eqnarray}
Then $(\delta p_2,\delta \bv_2)=(p_0-p_2,\bv_0-\bv_2)$ solves
\begin{eqnarray}
\label{eqn:awe2}
  \frac{1}{\kappa}\frac{\partial \delta p_2}{\partial t} & = & -
                                                               \nabla
                                                               \cdot
                                                               \delta \bv_2, \nonumber \\
  \rho\frac{\partial \delta \bv_2}{\partial t} & = & - \nabla \delta p_2,\nonumber \\
  \delta p_2 & =& p_0,  \mbox{ for } t=T,\nonumber\\ 
  \delta \bv_2 & = & \bv_0 \mbox{ for } t=T,\nonumber\\
  P_r\delta p_2 = 0. 
\end{eqnarray}
Using the standard energy estimate for homogenous Dirichlet
problem,
\begin{equation}
  \label{eqn:errtr}
  E[{\bf 1}_{\bR^2 \times (-\infty,z_r]}(\delta p_2,\delta \bv_2)](t) \le
  \epsilon E[(p_0,\bv_0)], \, 0 \le t \le T.
\end{equation}

Define $T^{-}P_rp_0 = P_sp_2$. Then
\[
  T_{z_r,z_s}^{-}P_rp_0-P_sp_0 = P_s\delta p_2.
\]
For the time being, write $O(\epsilon)$ for errors in the trace at
$z_s$ (output of $P_s$) for solutions of the forward Dirichlet problem
for initial data satisfying the estimate \ref{eqn:errtr}. Of course
this does not imply any $L^2$ bound on the trace - for that,
additional constraints on the initial data are required, to be
discussed below. With this convention,
\[
  T_{z_r,z_s}^{-}P_rp_0 =
  S^{-}_{z_r,z_s}(\Lambda^{-}_{z_r})^{-1}P_rp_0
\]
\[
  =  S^{-}_{z_r,z_s}(\Lambda^{-}_{z_r})^{-1}T_{z_s,z_r}^+P_sp_0
\]
\[
=
S^{-}_{z_r,z_s}(\Lambda^{-}_{z_r})^{-1}S_{z_s,z_r}^+(\Lambda^{+}_{z_s})^{-1}P_sp_0
\]
\[
  = P_s p_0 + O(\epsilon)
\]
Setting $h_s= +(\Lambda^{+}_{z_s})^{-1}P_sp_0$ and applying
$+(\Lambda^{+}_{z_s})^{-1}$ to both sides, obtain
\[
  h_s =
  (\Lambda^{+}_{z_s})^{-1}S^{-}_{z_r,z_s}(\Lambda^{-}_{z_r})^{-1}S_{z_s,z_r}^+h_s
  + O(\epsilon)
\]
\[
  =
 -(\Lambda^{+}_{z_s})^{-1}(S^{+}_{z_r,z_s})^T(\Lambda^{-}_{z_r})^{-1}S_{z_s,z_r}^+h_s
  +O(\epsilon)
\]
\begin{equation}
  \label{eqn:approxunit}
 =(\Lambda^{+}_{z_s})^{-1}(S^{+}_{z_r,z_s})^T((\Lambda^{+}_{z_r})^{-1})^TS_{z_s,z_r}^+h_s
  +O(\epsilon)
\end{equation}
The last two steps are justified by appeal to identities
\ref{eqn:trtr} and \ref{eqn:ntodtr}.

Define
\begin{equation}
  \label{eqn:appinv}
  (S^+_{z_s,z_r})^{\dagger} =
  (\Lambda^{+}_{z_s})^{-1}(S^{+}_{z_r,z_s})^T((\Lambda^{+}_{z_r})^{-1})^T.
\end{equation}
Then equation \ref{eqn:approxunit} asserts that
$(S^+_{z_s,z_r})^{\dagger}$ is an approximate inverse to
$S^+_{z_s,z_r}$, in the sense that the error is the trace of a
ssolution with small Cauchy condition at $t=0$. Later will specify
conditions under which the output error is small in $L^2$.


\section{Progressing Waves and Symbols}

The symbol $\sigma(L[c])$ of a matrix operator $L[c]$ is a complex scalar-valued matrix of the same size. In terms of its product with an arbitrary vector $\bu \in \bR^{d+1}$, it is
\[
  \sigma(L[c]) \bu = e^{-i(\omega t + \bk \cdot \bx)} (L[c]e^{i(\omega t + \bk \cdot \bx)}\bu).
\]
For $L[c]$ given by the definition \ref{eqn:awemat}, obtain
\begin{equation}
  \sigma(L[c])(t,\bx,\omega,\bk) = i\left(
    \begin{array}{cc}
      \frac{\omega}{\kappa(\bx)} & \bk^T \\
      \bk & \rho(\bx) \omega)
    \end{array}
  \right)
\end{equation}

The characteristic equation of $L[c]$ is $\det \sigma(L[c]) = 0$. The significance of the characteristic equation is its role in constraining the phase $\psi(\bx)$ in the progressing wave ansatz,
\begin{equation}
  \label{eqn:go}
  \bu(\bx,t) = e^{i\omega (t-\psi(\bx))} \ba (\bx).
\end{equation}
Applying $L[c]$ to this ansatz, obtain
\[
  L[c]\bu(\bx,t)=i \omega
  \left(
    \begin{array}{c}
      \frac{1}{\kappa}a_p -  \nabla \psi \cdot \ba_v \\
      -a_p \nabla \psi + \rho \ba_v
    \end{array}
  \right) + ...
\]
\[
  = i \omega \sigma(L[c])(t,\bx,1,- \nabla \psi(\bx))ba + ...
\]
where ``$...$'' denotes terms of lower order in $\omega$. Thus $\bu$ as defined in equation \ref{eqn:go} is a high-frequency asymptotic solution, $L[c]\bu \approx 0$, if
\begin{itemize}
\item
  \begin{equation}
    \label{eqn:eik}
    \det(\sigma(L[c])(t,\bx,1,-\nabla \psi(\bx))) = 0,
  \end{equation}
  (eikonal equation), and
\item
  $\ba$ is a null vector of $\sigma(L[c])(t,\bx,1,-\nabla \psi)$.
\end{itemize}
Explicitly, the eikonal equation reads
\[
  0 = \rho^2\left(\frac{\rho}{\kappa}-|\nabla \psi|^2\right),
\]
equivalent to the familar form
\begin{equation}
  \label{eqn:usualeik}
  c|\nabla \psi| = 1,
\end{equation}
in which $c = \rho/\kappa$ is the wave velocity. Solution via the method of characteristics gives
\[
  \psi(\bx(t)) = \psi(\bx(0)) + t
\]
for a ray $t \mapsto \bx(t)$ satisfying
\[
  \frac{d\bx}{dt}(t) = -c(\bx)^2\nabla \psi(\bx(t))
\]
Finally, $\ba$ is a null vector of $\sigma(L[c])(\cdot,\cdot,1,-\nabla \psi)$ iff
\begin{equation}
  \label{eqn:godton}
  \ba_v = \frac{a_p}{\rho}\nabla \psi
\end{equation}
The scalar $a_p$ evolves along the ray according to the transport equation, which I will not derive here; suffice it to say that $a_p(t) = a_p(0) \gamma(t)$, where $\gamma > 0$ is smooth and $\gamma(0)=1$.

Suppose that $\bx_0 = (x,y,z_s)^T$ and $(\xi_x,\xi_y) \in \bR^2$ satisfies $c(\bx_0)|(\xi_x,\xi_y)|<1$. Then there is a neighborhood $\Omega$ of $\bx_0$ and $\xi_z \in C^{\infty}(\Omega), \xi_z>0$, so that $\bxi^{\pm}(\bx)=(\xi_x,\xi_y,\pm \xi_z(\bx))$ satisfy $c(\bx)|\bxi^{\pm}(\bx)|=1$ for $\bx \in \Omega$.

A standard argument shows that there exists $\epsilon > 0$ for which a solution $\psi^{\pm}$ of the eikonal equation exists in $\Omega \cap \{\bx: |z-z_s|<\epsilon\}$ with
\begin{equation}
  \label{eqn:eikic}
  \psi^{\pm}(x,y,z_s,t) = t -x \xi_x - y \xi_y, \, \frac{\partial \psi}{\partial z}(x,y,z_s,t) = \pm \xi_z(x,y,z_s).
\end{equation}
Let $\chi \in C_0^{\infty}, \chi(\bx_0)=1$, and set $p_0^{\pm}(x,y,t) = \chi(x,y,z_s)e^{i\omega(t-x\xi_x - y\xi_y)}$. Define $p_{\rm go}^{\pm} \in C^{\infty}(\Omega \cap \{\bx: |z-z_s|<\epsilon\})$ by
\[
  p_{\rm go}^{\pm}(\bx,t) = a^{\pm}_p(\bx) e^{i\omega (t-\psi^{\pm}(\bx))}.
\]
where $a^{\pm}_p$ solves the transport equation with $a^{\pm}_p|_{z=z_s} = \chi$. Set
\[
  \bv^{\pm}_{\rm go}(\bx,t) = \frac{a^{\pm}_p(\bx)}{\rho(\bx)}\nabla \psi^{\pm}(\bx) e^{i\omega (t-\psi^{\pm}(\bx))}
\]
Then $\bu^{\pm}_{\rm go} = (p^{\pm}_{\rm go}, \bv^{\pm}_{\rm go})$ is an asymptotic solution of $L[c]\bu = 0$ with $p^{\pm}_{\rm go}|_{z=z_s} = \chi e^{i\omega(t-x\xi_x - y\xi_y)}$.

From equations \ref{eqn:godton} and \ref{eqn:eikic},
\[
  v_{z,{\rm go}}^{\pm}(x,y,z_s,t) = \pm \frac{\chi(x,y,t)}{\rho(x,y,z_s)}\xi_z  e^{i\omega(t-x\xi_x - y\xi_y)}
\]
\begin{equation}
  \label{eqn:asymdton}
= \pm \frac{\chi(x,y,t)}{\rho(x,y,z_s)c(x,y,z_s)}\sqrt{1-c(x,y,z_s)^2(\xi_x^2+\xi_y^2)}
\end{equation}

Integration over frequency produces a progressing wave traveling (at least near $z=z_s$) downwards, that is, increasing $z$ with increasing $t$, for the choice of sight $\pm = +$, and upwards, that is, decreasing $z$ with increasing $t$, for the other sign. Therefore a causal progressing wave with $p$ given on $z=z_s$ is obtained by synthesizing distorted plane waves as just described with $\pm = +$ in $z>z_s$, $\pm=-$ in $z<z_s$. From equation \ref{eqn:asymdton}, the normal components of $\bv$ have limits equal in magnitude but of opposite sign as $z\rightarrow 0^{\pm}$, up to a lower frequency error. That is, the jump in $\bv$ satisfies
\begin{equation}
  \label{eqn:asymjump}
  [v_z]\approx 2\lim_{z\rightarrow 0^+} v_{z}
\end{equation}
where $\approx$ denotes ``up to a low frequency error'', from here on.

This construction also implies an approximation of the source-to-pressure operator as a pseudodifferential operator. Choose a partition of unity in $z=z_s$, for which the support of every member is a domain $\Omega$ for which the construction above can be carried out: this implies that there be a uniform $\delta > 0$ so that
\begin{equation}
  \label{eqn:nongraze}
  1>\delta + c(x,y,z_s)\sqrt{\xi_x^2+\xi_y^2}
\end{equation}
for all $(x,y,t,1,\xi_x,\xi_y) \in WF(p_0)$. Denote by $\Gamma$ the subset of $(x,y,t,k_x,k_y,\omega) \in T^*(\bR^3)$ for which $x,y,\xi_{xy}=k_{xy}/\omega$ satisfy the inequality \ref{eqn:nongraze}.

Then near $z=z_s$, $p$ is approximately a sum of geometric optics solutions of the type displayed above, integrated over $\omega,k_x,k_y$, with $k_{x,y} = \omega \xi_{x,y}$.  Thus
\[
  p(x,y,z_s,t) \approx \frac{1}{2}\int_{\Gamma(x,y)} \,d\omega\,dk_x\,dk_y \hat{[v_z]}\rho(x,y,z_s)c(x,y,z_s)
\]
\[
   \times \left(1-c^2(x,y,z_s)\left(\left(\frac{k_x}{\omega}\right)^2 + \left(\frac{k_y}{\omega}\right) ^2\right)\right)^{-1/2}e^{\i(\omega t + k_x x+ k_y y)}
\]
Since $p$ is the pressure component of a solution of \ref{eqn:awep}, equation \ref{eqn:sourcevjump} implies that
\begin{equation}
  \label{eqn:psidodton}
  \Lambda^+_{z_s} h_s(x,y,t) \approx \frac{1}{2}\int_{\Gamma(x,y)} \,d\omega\,dk_x\,dk_y
  \lambda_s(x,y,t,k_x,k_y,\omega) \hat{h_s}(k_x,k_y,\omega) e^{\i(\omega t + k_x x+ k_y y)}
\end{equation}
with
\begin{equation}
  \label{eqn:symboldton}
  \lambda^+_{z_s}(x,y,t,k_x,k_y,\omega) =\frac{1}{2}\rho(x,y,z_s)c(x,y,z_s)\left(1-c^2(x,y,z_s)\left(\left(\frac{k_x}{\omega}\right)^2 + \left(\frac{k_y}{\omega}\right) ^2\right)\right)^{-1/2}
\end{equation}

Restricted to $\Gamma$, $\lambda^+_{z_s} \in S^0_{0,1}(\bR^2)$ is real-valued, hence defines an essentially symmetric operator. That is,
\begin{equation}
  \label{eqn:approxsymm}
  (\Lambda^+_{z_s})^T \approx \Lambda^{+}_{z_s}.
\end{equation}

Note that the defintion \ref{eqn:appinv} of $ (S^+_{z_s,z_r})^{\dagger} $ is that of
the transpose of $S^+_{z_s,z_r}$ in the sense of weighted norms, as
follows. Define trace spaces $W=L^2(\bR^2 \times [0,T])$, with inner product
\[
  \langle h_1,h_2\rangle_s = \langle
  h_1,\frac{1}{2}(\Lambda^+_{z_s}+(\Lambda^+_{z_s})^T)h_2\rangle
\]
and $D=L^2(\bR^2 \times [0,T])$ with inner product
\[
  \langle d_1,d_2\rangle_r = \langle
  d_1,\left(\frac{1}{2}(\Lambda^+_{z_s}+(\Lambda^+_{z_s})^T)\right)^{-1}d_2\rangle
\]
(These definitions must be supplemented with constraints on
out-of-aperture smoothness). Then the adjoint of $S^+_{z_s,z_r}: W
\rightarrow D$ is
\[
 \left(\frac{1}{2}
   (\Lambda^+_{z_s}+(\Lambda^+_{z_s})^T)\right)^{-1}(S^+_{z_s,z_r})^T
 \left(\frac{1}{2}(\Lambda^+_{z_r}+(\Lambda^+_{z_r})^T)\right)^{-1}
\]
 By virtue of the approximation \ref{eqn:approxsymm}, this is
\[
   \approx
   (\Lambda^{+}_{z_s})^{-1}(S^{+}_{z_r,z_s})^T((\Lambda^{+}_{z_r})^{-1})^T
   = (S^+_{z_s,z_r})^{\dagger}.
\]
which from the last section is approximately inverse to
$S^+_{z_s,z_r}$. That is, with the domain and range described above,
$S^+_{z_s,z_r}$ is approximately unitary.

\section{Efficient Preconditioned CG}

\cite{HouSymes:EAGE16} demonstrated a very similar preconditioner for Least Squares Migration, also for its subsurface offset extension \cite[]{HouSymes:16}, motivated by \cite{tenKroode:12}. These constructions all involve the Dirichlet-to-Neumann operator. This concept also turns up in hidden form in the work of Yu Zhang and collaborators on true amplitude migration \cite[]{YuZhang:14,TangXuZhang:13,XuWang:2012,XuZhangTang:11,Zhang:SEG09,Zhang YuSun:08,ZhangSunGray:07,ZhangBleistein:05,Bleisteinetal:05}. 

The discussion so far can be summarized as follows: an efficient pseudoinverse for $S[c]$ is the weighted adjoint operator
\begin{equation}
\label{eqn:wadj}
S[c]^{\dagger} = W[c]_m^{-1}S[c]^TW[c]_d,
\end{equation}
in which 
\begin{equation}
\label{eqn:weights}
W[c]_m = \kappa^{-1}\Lambda[c]^{-1}_s,\,\, W[c]_d = \kappa^{-1}\Lambda[c]_r
\end{equation}
Here ``$\kappa$'' means the operator ``multiply by $\kappa$''.

The statement that $S[c]^{\dagger}$ is the weighted adjoint of $S[c]$ means that $S[c]^{\dagger}$ {\em is} the adjoint of $S[c]$ with respect to weighted norms 
\begin{itemize}
\item on the source space ($h_s$): weight $W[c]_m$
\item on the data space ($d_r$): weight $W[c]_d$
\end{itemize}
Since $S[c]^{\dagger}S[c] \approx I$ in subspaces of the domain space, as shown above, $S[c]$ is approximately unitary in (subspaces of) the Hilbert spaces of source and data traces with norms defined by the weighting operators $W_m$ and $W_d$ respectively. Therefore a Krylov space method employing these norms will converge rapidly, at least for the well-determined components of the solution.

The most convenient arrangement the CG algorithm taking advantage of the structure \ref{eqn:wadj} is the {\em Preconditioned CG}. Since the coefficient array $c$ will remain unchanged during the iteration, write $S$ instead of $S[c]$, etc. 

Allowing that the fit error will be measured by the data space norm, the least squares problem to be solved is not just $Sh \approx d$, but a regularized version:
\begin{equation}
  \label{eqn:einv}
  \mbox{minimize}_h \|Sh-d\|^2_d + \alpha^2 \|Ah\|^2_m
\end{equation}

[The modified data space norm $\|d\|_d^2 = \langle d, W_d d\rangle$ has physical meaning: for acoustics, it is proportional to the power transmitted through the surface $z=z_r$.]

The minimizer of the objective defined in equation \ref{eqn:einv} solves the normal equation
\begin{equation}
  \label{eqn:norm}
  (S^{\dagger}S + \alpha^2 A^{\dagger}A)h = S^{\dagger}d 
\end{equation}

where the weighted adjoint $S^{\dagger}$ has already been defined in equation \ref{eqn:wadj}, and $A^{\dagger}$ is the adjoint of $A$ in the weighted model space norm defined by $W_m$, namely
\begin{equation}
  \label{eqn:aadj}
  A^{\dagger} = W_m^{-1}A W_m.
\end{equation}

Introducing these definitions in the normal equation \ref{eqn:norm},
\begin{equation}
  \label{eqn:norm1}
  W_m^{-1}(S^TW_dS + \alpha^2 A^TW_mA)h = W_m^{-1}S^TW_md 
\end{equation}
Since $W_m$ is self-adjoint and positive definite, the common factor on both sides of \ref{eqn:norm1} can be re-written as

write $S^*, A^*$ for the adjoints with the original (Euclidean) inner product in the domains but the weighted inner product in data space:
\begin{equation}
  \label{eqn:normpart}
  Nh = (S^*S + \alpha^2 A^*A)h = S^*d 
\end{equation}
using the ``partly weighted'' adjoints
\begin{eqnarray}
  \label{eqn:sadj}
  S^* &=& S^T W_d,\\
  A^* &=& A^T W_m.
\end{eqnarray}
The Preconditioned Conjugate Gradient (``PCG'') algorithm for solution of equation \ref{eqn:normpart} with preconditioner $W_m$ is usually written as Algorithm 1.

\begin{algorithm}[H]
\caption{Preconditioned Conjugate Gradient Algorithm, Standard Version}
\begin{algorithmic}[1]
\State Choose $h_0=0$ 
  \State $r_0 \gets S^*d$
  \State $p_0 \gets W_m^{-1}r_0$
  \State $g_0 \gets p_0$
  \State $q_0 \gets Np_0$
  \State $k \gets 0$
  \Repeat
  \State $\alpha_k \gets \frac{\langle g_k,r_k \rangle}{\langle p_k,q_k\rangle}$
  \State $h_{k+1} \gets h_k + \alpha_k p_k$
  \State $r_{k+1} \gets r_k - \alpha_kq_k$
  \State $g_{k+1} \gets W_m^{-1}r_{k+1}$
  \State $\beta_{k+1} \gets \frac{\langle g_{k+1},r_{k+1}\rangle}{\langle g_k,r_k\rangle}$
  \State $p_{k+1}\gets g_{k+1}+\beta_{k+1}p_k$
  \State $q_{k+1} \gets Np_{k+1}$
  \State $k \gets k+1$
  \Until{Error is sufficiently small, or max iteration count exceeded} 
\end{algorithmic}
\end{algorithm}

The operator whose eigenvalue spectrum determines the speed of convergence here is the preconditioned normal operator
\begin{equation}
  \label{eqn:pno}
  W_m^{-1}N = S^{\dagger}S +\alpha^2 A^{\dagger}A
\end{equation}
This isn't just an approximate identity on a subspace, as $S^{\dagger}S$ is. The addition of the penalty term affects the spectrum, pushing parts of it away from $1$. I have not yet analyzed this effect, however for the ``in-aperture'' part of the model space,
\[
  W_m^{-1}N \approx I +\alpha^2 W_m^{-1}A^TW_mA
\]
For small $\alpha$, this operator is a perturbation of the spectrum of the identity, so convergence should be rapid. 

In the preceding section, I showed that effective choices for the weight operators are $W_m = \Lambda_s^{-1}$ and $W_d = \Lambda_r$, which are resepctively the ``Neumann-to-Dirichlet'' operator mapping pressure to normal particle velocity on the source surface $\{z=z_s\}$, and the ``Dirichlet-to-Neumann'' operator mapping pressure to normal particle velocity on the receiver surface. Application of these operators are expensive and/or awkward, so should be avoided if at all possible. 

A very important point: the weighted ``partial'' adjoint $S^*=S^TW_d$ appears {\em only} in combination with $S$ in the algorithm listed above, {\em except} for the very first line. That is, one can calculate $W_dS$ followed by $S^T$, rather than $S$ followed by $S^TW_d$, provided that you can take care of the first line. $W_dS$ For any variant of elasticity, $W_d$ relates two combinations of dynamical field components - for acoustics, it returns the normal velocity for a given pressure field on the receiver surface. In the solution of the dynamical equations (for instance \ref{eqn:awe}), all components are calculated. Therefore obtaining the output of $W_d$ amounts to extracting the appropriate field combination. For acoustics, simply record the normal velocity rather than the pressure: then you have computed $W_dS$. Therefore no additional expensive computations are required. It is only the very first instance of $S^*$, on the first line, where an actual computation of $W_d$ is required, unless cheap workarounds like that explained by \cite{HouSymes:15} are available.

\section{Prototype Numerical Examples}
I present a collection of simple examples that illustrate the features of the surface source extension claimed in preceding sections. 

I used the IWAVE acoustic staggered grid package to carry out these calculations. This package implements (2,2k) schemes for k=1,2,..., and outputs traces (of either velocity or pressure at any point in space via multilinear interpolation. The discretized modeling operator is thus of second order accuracy, though as usual I have used higher order in space to reduce grid dispersion.

Source injection is implemented as the adjoint of trace sampling, resulting in another second-order error [REFERENCES]. 

The data is a single shot gather, with a source at coordinates $x_s=z_s=3000$ m (units of length are meters in all cases). The receiver line occupies $1500 \le x_r \le 5500$ m, with receiver depth $z_r=1000$ m.  Extended sources occupy $1500 \le x_s \le 5500$ m, with the same depth $z_s=3000$ m as the ``physical'' source used to generate the data. This region turns out to be adequate to represent the extended sources that approximately invert the data, for the cases examined below. An algorithm to automatically identify an appropriate region can be based on the ideas developed by \cite{Fu:Geo17}.

I have used absorbing boundary conditions (split-field PML) on all four sides of the 4000 m (vertical) $\times$ 8000 m (horizontal) simulation domain. Evidently inclusion of a free surface is important to the application of the ideas explained here to diving wave marine data, and I have not addressed the necessary modifications here. 

The Dirichlet-to-Neumann operator $\Lambda$ is an essential part of the inner problem preconditioner just presented. Implementation can be accomplished in several ways:
\begin{itemize}
\item \cite{tenKroode:12} suggests using a one-way operator;
\item if both pressure and normal partical velocity are measured (or simulated), then the two are related by $\Lambda$ and the velocity component can simply be used as the output;
\item presence of a free surface implies all of the usual problems, such as the need for removal of receiver-side ghosts. On the other hand, if the free surface is within a quarter-wavelength throughout the useful bandwidth of the data, then the ghosted data differs from $\Lambda p$ by a time integration and a scale factor, a fact used to good effect by \cite{HouSymes:15}.
\end{itemize}

In the examples, I have used the second observation. With a finite difference implementation of the pressure-velocity system \ref{eqn:awe}, velocity components are available ``for free'', short-circuiting explicit computation of $\Lambda$.

The  {\tt project/SConstruct} script is set up to carry out the necessary computations on grids with spacings $\Delta x = \Delta z = $ 20, 10, and 5 m, with a jump of roughly 8 in computation time resulting from each refinement. For present purposes, the coarsest (20 m) grid seems to be sufficient, and that is the grid used in the examples presented below. The source pulses are chosen so that the computation is reasonably accurate. For the 20 m grid case, I use a zero-phase trapezoidal bandpass filter source with corner frequencies of 1.0, 2.0, 7.5, and 12.5 Hz.

The IWAVE asg driver has been set up to recognize the case {\tt deriv=0} as defining the map from source (right-hand side in the pressure equation) to data (pressure) traces. The adjoint to this map, as explained above, is reverse-time propagation of the data traces as pressure sources, followed by scaling (formula \ref{eqn:sadj}). The approximate inverse is computed by application of the Dirichlet-to-Neumann operator to the pressure traces to produce corresponding velocity traces, followed by injection as pressure sources and reverse time propagation, followed by another application of the Dirichlet-to-Neumann map and scaling (formulas \ref{eqn:appinv}, \ref{eqn:adj}).

The script implements these operatations step-by-step via calls to IWAVE, Madagascar, and SU commands. A peculiarity of the {\tt asg.x} driver needs to be mentioned: it is based on an un-scaled version of the constitutive law defect source representation, that is, {\tt asg.x} approximately computes the solution of the system \ref{eqn:awedata} with the first equation replaced by
\begin{equation}
\label{eqn:asgdata}
\frac{\partial p}{\partial t}  =  - \kappa \nabla \cdot \bv +
h \delta(z-z_s).
\end{equation}
Denote by $S_{\rm asg}[c]$ the forward map produced by {\tt asg.x}. Then comparison of \ref{eqn:awedata} and \ref{eqn:asgdata} reveals that
\begin{equation}
\label{eqn:sreln}
S[c]=S_{\rm asg}[c]\kappa
\end{equation}
where $\kappa$ is shorthand for the operator of multiplication by $\kappa$. Accordingly, and approximate inverse for $S_{\rm asg}[c]$ is
\[
I \approx S_{\rm asg}[c]^{\dagger}S_{\rm asg}[c] = S_{\rm asg}[c]^{\dagger}S[c]\kappa^{-1}
\]
Since $S[c]S[c]^{\dagger} \approx I \approx S[c]^{\dagger}S[c]$, it follows that
\[
S_{\rm asg}[c]^{\dagger}=\kappa S[c]^{\dagger} = \kappa\Lambda[c]_s S[c]^T \Lambda[c]_r 
\]
\begin{equation}
\label{eqn:asginv}
= \kappa \Lambda[c]_s \kappa S_{\rm asg}[c]^T\Lambda[c]_r
\end{equation}
This is the approximate inverse computed in the examples. Note that only the values of $\kappa$ near the source datum $z=z_s$ play a role in the relation \ref{eqn:sreln} or in the definition \ref{eqn:asginv} of the IWAVE ASG approximate inverse.
\bibliographystyle{seg}
\bibliography{../../bib/masterref}


\bibliographystyle{seg}
\bibliography{../../bib/masterref}
