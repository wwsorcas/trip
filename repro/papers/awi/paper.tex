\title{Adaptive Waveform Inversion for Transmitted Wavefields}
\author{William W. Symes}

\begin{abstract}
Adaptive Waveform Inversion
applied to transient transmitted wave data yields estimates of index of
refraction (or wave velocity) similar to those obtained by travel time
inversion, provided that the data contain a single smooth wavefront.
\end{abstract}

\section{Introduction}
Full waveform inversion (FWI) refers to the inference of mechanical
parameter distribution within a material object  (the earth, a human
body, a manufactured artifact,...) from the measurement of wave motion
at its surface. Over the last several decades, this task has come to
be carried out by minimizing a measure of the difference between computational
prediction of wave data versus actual observed
data. The mechanical parameters to be inferred appear as
coefficients in systems of partial differential equations governing
the wave motion, and discrete representations of these parameters form
the unknown vectors in the optimization problems thus generated.

While widely used in recent years, FWI exhibits a pathology when wave
velocities or their parametric equivalents are amongst the parameters
to be estimated: the excessive sensitivity of predicted waveforms to
changes in velocity leads to oscillations in the difference measures,
especially for the most commonly used mean-square measure. Local
optimization algorithms (relatives of Newton;'s method) are the only practical
methods to generate sequences of approximate optimal
parameters. However the oscillations in the difference measures lead
these sequences to become entrapped at near parameter distributions
far from the optimum, and thus do not extract the maximum information
from the data \cite[]{VirieuxOperto:09}. 

Various modifications of straighforward best-fit FWI have been
suggested to overcome this ``cycle-skipping'' pathology. One of these
is Adaptive Waveform Inversion \cite[]{Warner:16} (AWI). This
technique has been successfully applied to industry-scale seismic data
\cite[]{GuaschWarnerRavaut:GEO19,Warneretal:SEG21} and shows promise for
ultrasonic imaging of the the human brain
\cite[]{Guaschetal:NPJDM20}.

While these and other works discuss heuristic justifications for AWI and
many details of implementation, a clear explanation for its effectiveness is 
so far missing from the literature. In this short note, I show that
for active sensing of acoustic materials with unique arrival times of
transmitted waves
(that is, unique rays of geometric asymptotics between sources and
receivers), the AWI objective function is an asymptotic (in time
frequency) approximation to the
mean-square time-of-travel misfit. Thus AWI and travel time fitting
lead to similar material parameter estimates. Since the latter is
widely believed to be a near-optimal method for wave velocity
estimation, this demonstration explains roughly ``why AWI works'', at
least within this restricted scope.

The reader will
note that a normalization component of the AWI objective function
definition is 
important in reaching this conclusion. The connection between
objective normalization and the asymptotic equivalence to travel time
inversion for transmission data has nothing to do with
the reasons for normalizing the objective previoiusly advanced in the
literature \cite[]{Warner:16,LiAlkhalifah:21}. Another modification of
FWI based on similar ideas, Matched Source Waveform Inversion (MSWI)
(\cite{HuangSymes2015SEG,HuangSymes:Geo17}) lacks the AWI normalization,
and has a looser relation to travel time inversion. The arguments
presented here for AWI (and MSWI) are refinements of those given by
\cite{HuangSymes:Geo17}. which were in turn based on ideas presented in Song's thesis
\cite[]{Song:94c}.

After establishing the class of problems to be studied and notations
for their description in the following section, I present the
asymptotic analysis leading to the main conclusion in the next. In
effect, AWI regularizes or relaxes the FWI problem. For many inverse
problems, regularization has been accomplished via additive penalty
functions. In section four, I explain the relation between AWI and a
penalty formulation of the wave inverse problem. The
close relation between AWI objective and travel time misfit is limited
in scope: in the fifth section, I show that it does not hold in
general for transmitted wave data in which multiple rays connect
source and receiver. 

The analysis explained here sheds no light on the effectiveness of AWI
for reflected wave data, and the approach has so far been limited
inversion of data modeled by acoustic wave propagation. I discuss
these and other aspects of AWI and related approaches in a brief final
section.

\section{Adaptive Waveform Inversion}

The version of AWI introduced by \cite{Warner:16} is based on an
active source acoustic model of data generation. Each acoustic source
is modeled an isotropic point radiator with known location $\bx_s$ and
wave form (``wavelet'') $w(t;\bx_s)$. Similarly, receivers are modeled
as isotropic point sensors, recording pressure at points ${\bf x}_r$. The pressure and velocity fields $p({\bf x},t;{\bf x}_s)$, ${\bf v}({\bf x},t;{\bf x}_s)$ for the source location ${\bf x}_s$ depend on the bulk modulus $\kappa({\bf x})$, buoyancy $\beta({\bf x})$ (reciprocal of the density $\rho({\bf x})$), and wavelet $w(t;{\bf x}_s)$ through the acoustic system
\begin{eqnarray}
  \label{eqn:awe}
 \frac{\partial p}{\partial t} & = &- \kappa \nabla \cdot {\bf v} +
w(t;{\bf x}_s) \delta({\bf x}-{\bf x}_s); \nonumber \\
\frac{\partial {\bf v}}{\partial t} & = & - \beta \nabla p; \\ 
p, {\bf v} & = & 0 \mbox{ for }  t \ll 0.
\end{eqnarray}
For sake of brevity, define the model vector $m=(\kappa,\rho)$. The forward map or {\em modeling operator} is $F[m]w = \{p({\bf x}_r,t;{\bf x}_s)\}$, in which source and receiver positions ${\bf x}_s, {\bf x}_r$ define the acquisition geometry.

Acoustic inversion, for present purposes, means: given source and receiver locations $(\bx_s,\bx_r)$, source wavelet
$w(t;\bx_s)$ and data traces $d(\bx_r,\cdot;\bx_s)$, find a model $m$
so that $F[m]w \approx d$. The
simplest version of FWI concretizes this task by asking for a model
$m$ minimizing the mean square error
\begin{equation}
  \label{eqn:fwi}
  J_{\rm FWI}[m;d] =\frac{1}{2} \sum_{{\bf x}_r,{\bf x}_s} \int\,dt\, |(F[m]w)({\bf x}_r,t;{\bf x}_s) - d({\bf x}_r,t;{\bf x}_s)|^2
\end{equation}
It is convenient to introduce the $L^2$ norm $\| \cdot \|$ as
shorthand for the right-hand side of the definition \ref{eqn:fwi}:
\[
  J_{\rm FWI}[m;d]= \frac{1}{2}\|F[m]w-d\|^2.
\]
In the sequel I will use the $L^2$ norm notation to stand for
mean-square over whatever variables make sense.

Note that in actual data acquisition, recording occurs over finite
time intervals, so the integrals appearing in the definition
\ref{eqn:fwi} have finite upper and lower limits, as opposed to the
$\pm \infty$ limits implicit in the notation. It will be assumed that
wavefield energy is causal (zero before an onset time) and decays
rapidly enough as $t \rightarrow \infty$ that the difference between
finite and infinite range of integration can be ignored throughout
this discussion.

The wavelet $w$ is assumed known in this formulation of the
FWI problem. In fact, even if actual acoustic sources are
well-approximated by isotropic point radiators, their wave forms are
usually poorly determined and may reasonably be
included as  parameters to be estimated by inversion of the
data. However for the present discussion we will regard $w$ as known.

Practical versions of FWI include various types of regularization and
imposition of constraints on $m$, see the sources cited in the
Introduction. As mentioned there, local iterative optimization methods
are the only practical approach to minimizing $J_{\rm FWI}$ due to the
computational cost of approximating the forward map $F$ and related
operators, but these tend to stagnate at highly sub-optimal
(``cycle-skipped'') estimates of $m$ unless the initial estimate is of
quite high quality, often available only at considerable cost in data
collection and processing.
%For now, assume that the data $d({\bf x}_r,t;{\bf x}_s)$ is the output of the modeling operator for "true" model $m^*$, that is, the "true" bulk modulus, buoyancy, and wavelet $\kappa^*, \beta^*, w^*$: that is, $d = F[m^*]w^*$.

AWI is based on extending the modeling operator $F$, that is, enlarging its domain.
The extended modeling operator ${\bar F}$ maps extended sources
$\bar{w}({\bf x}_r,t;{\bf x}_s)$ to the same sampling of the pressure
field. That is, the extended source depends on the receiver location
as well as the source location - so there is one acoustic system for
each source {\em and} receiver position - a lot of wave equations! If all
of the wavelets for each source are the same, that is, ${\bar w}({\bf
  x}_r,t;{\bf x}_s) = w(t;{\bf x}_s)$ is independent of receiver
position, then ${\bar F}[m]\bar{w} = F[m]w$. That is, $F$ is a special
case, or restriction, of ${\bar F}$, so ${\bar F}$ is an extension of
$F$. This is the {\em source-receiver} extension, in the terminology of \cite{HuangSymes2015SEG}.

AWI assumes that the extended sources are time convolutions of the
(known) source $w$ with an {\em adaptive filter} $u({\bf
  x}_r,t;{\bf x}_s)$: that is,
\[
  \bar{w}({\bf x}_r,t;{\bf x}_s) = (u * w)({\bf  x}_r,t;{\bf x}_s)
  = (u({\bf  x}_r,\cdot;{\bf x}_s)*w)(t).
\]
The asterisk denotes convolution in time. That is,
$u*w$ denotes the result of convolving each trace in $u$ by $w$. I
will also use the asterisk to denote the tracae-by-trace convolution
of two data sets with the same set of source and receiver coordinates,
that is, the data set consisting of time convolutions of traces with the same source
and receiver coordinates. The meaning will be clear from context.

Since linear acoustics is time-translation invariant, its solution commutes with time convolution, that is,
\[
 \bar{F}[m]\bar{w} = \bar{F}[m](u* w) = (F[m]w)*u
\]
Since the known source $w$ is not adjusted during the inversion, 
introduce the notation $S[m]$ for the convolution operator with kernel $F[m]w$:
\begin{equation}
  \label{eqn:sdef}
  (F[m]w)*u \equiv S[m]u
\end{equation}
\cite{Warner:16} assume (implicitly) that there is always an exact
solution of the extended inversion problem. That is, they assume that
for any $m$, there is an extended source $\bar{w}$, or equivalently an
adaptive filter $u[m;d]$ with $\bar{w}=w*u[m;d]$, for which
$S[m]u[m;d]= d$. This proposition is dubious, but is easy to work
around, as will be seen below. Also, \cite{Warner:16} also formulate
AWI in terms of the inverse filter, that is, $u$ for which
$u*d = F[m]w$, and in fact recommend that definition. The present
discussion uses only the forward filter.

If $\kappa = \kappa^*, \beta = \beta^*$, then $\bar{w}$ should be $= w$,
so the adaptive kernel $u[m;d]$ should be $=\delta(t)$ for all
${\bf x}_s,{\bf x}_r$. Such a kernel $u[m;d]$ is in the null space of
multiplication by $t$.

This observation leads to the definition of the AWI objective function $J_{\rm AWI}$:
\begin{equation}
  \label{eqn:tJz}
  J_{\rm AWI}[m;d] = \sum_{\bx_s,\bx_r} \left(\frac{\int dt |tu[m;d](\bx_r,t;\bx_s)|^2}{\int dt |u[m;d](\bx_r,t;\bx_s)|^2}\right)
\end{equation}
in which $u[m;d]$ is as defined above, that is, the solution of $S[m]u[m;d]
= d$.

Adaptive waveform inversion consists in iterative minimization of
$J_{\rm AWI}$: choose an initial estimate $m_0=(\kappa_0,\beta_0)$ of the
model, then update $m=(\kappa,\beta)$ repeatedly using a gradient
descent method. \cite{Warner:16} describes the computation of $J_{\rm AWI}$
and its gradient in detail, and their use in a quasi-Newton
optimization algorithm.

The trace-by-trace normalization in definition \ref{eqn:tJz} of each
trace in $tu[m;d]$ by the
$L^2$ norm of the corresponding trace in $u[m;d]$ is quite important, as will be explained shortly.

\section{Why it works}

It may not be obvious at first glance why this approach to estimating
$m$ should be any more effective than FWI. To see why AWI works, in at
least some settings, we assume that the spatial dimension is three,
and make use of the geometric asymptotics (ray theory) approximation
to the solution of the wave equation. This approximation is {\em
  local}: it applies when sources and receivers are sufficiently
close. We will discuss its global failure and the consequences for AWI
in the final section.

Transient acoustic sources have no DC (zero frequency) component and
are relatively small at low frequencies. One way to enforce these
characteristics is to assume that the wavelet $w$ is the time
derivative of another wavelet $v$, also transient ($v(t;{\bf x}_s)=0$
for $|t| \gg 0$). Set $\lambda(w) = \|v\|/\|w\|$. $\lambda$ is a proxy
for wavelength: it is the reciprocal of RMS frequency of $v$.

The geometric asymptotics approximation for solution of the point
radiator problem \ref{eqn:awe} expresses the pressure field in terms
of $m$-dependent geometric amplitude $a[m]({\bf x}_s,{\bf x}_r)$ and
travel time $\tau[m]({\bf x}_s,{\bf x}_r)$, and implies that
\begin{equation}
  \label{eqn:hadamard}
  (F[m]w)({\bf x}_r,t;{\bf x}_s) \approx a[m]({\bf x}_s,{\bf x}_r) w(t-\tau[m]({\bf x}_s,{\bf x}_r)) 
\end{equation}
In this approximation, and in other uses of the symbol $\approx$, the
error is $O(\lambda(w))$.

Approximation \ref{eqn:hadamard} follows from a
``progressing wave''  expansion of the fundamental
solution (Green's function) of the wave equation due to Hadamard
\cite[]{Friedlander:75,Qian:JCP24}. For smooth (slowly varying)
$m$, it holds for $\bx_r$ sufficiently close to $\bx_s$ that a unique ray of
geometric acoustics connect $\bx_s$ to $\bx_r$. This ``single
arrival'' condition fails (in
general) at larger distance. The precise region of validity depends on
$m$. For the remainder of this section, its validity is assumed.

Applying the approximation \ref{eqn:hadamard}, obtain
\begin{equation}
  \label{eqn:spwe}
S[m]u({\bf x}_r,t;{\bf x}_s) \approx a[m]({\bf x}_s,{\bf x}_r) (w*u)(t-\tau[m]({\bf x}_s,{\bf x}_r))
\end{equation}
Assume that the data is noise-free:
$$
d({\bf x}_r,t;{\bf x}_s)=(F[m^*]w) ({\bf x}_r,t;{\bf x}_s) \approx a[m^*]({\bf x}_s,{\bf x}_r) w(t-\tau[m^*]({\bf x}_s,{\bf x}_r))
$$
The (approximate) solution of $S[m]u[m;d]=d$ is obvious by inspection:
\begin{equation}
  \label{eqn:notl2}
  u[m;d]({\bf x}_r,t;{\bf x}_s) = \frac{a[m^*]({\bf x}_s,{\bf x}_r)}{a[m]({\bf x}_s,{\bf x}_r)}\delta(t-\tau[m^*]({\bf x}_s,{\bf x}_r)+\tau[m]({\bf x}_s,{\bf x}_r)).
\end{equation}
There is immediately a big problem: this $u[m;d]$ is not
square-integrable, and the AWI objective $J_{\rm AWI}$ is
undefined. To fix this, it's necessary to replace $u[m;d]$ by
$u_{0,\sigma}[m;d]$,  the solution of a regularized least squares problem: 
\begin{equation}
  \label{eqn:reg}
  u_{0,\sigma}[m;d] = \mbox{argmin}_u (\|S[m]u-d\|^2 + \sigma^2\|u\|^2)
\end{equation}
$$
\approx \mbox{argmin}_u (\|a[m](w*u)(\cdot-\tau[m])-a[m^*]w(\cdot-\tau[m^*])\|^2 + \sigma^2\|u\|^2)
$$

Note that in these expressions, the source and receiver
coordinates ${\bf x}_s$ and ${\bf x}_r$ act as either passive parameters
or summation indices. Therefore, to simplify the presentation, drop them from the notation
temporarily. Also,  use the temporary abbreviations $a^*=a[m^*], a=a[m], \tau^*=\tau[m^*],
\tau=\tau[m]$.

With these conventions, re-write equation \ref{eqn:reg} in terms of the Fourier transforms $\hat{u}[m;d],\hat{w}$ of $u_{0,\sigma}[m;d]$ and $w$:
\begin{equation}
  \label{eqn:freqreg}
\hat{u}[m;d] \approx \mbox{argmin}_{\hat{u}}\left(\int d\omega |a\hat{w}\hat{u}e^{i\omega \tau}-a^*\hat{w}e^{i\omega\tau^*}|^2 + \sigma^2 |\hat{u}|^2\right)
\end{equation}
The normal equation for the least squares problem \ref{eqn:freqreg} is
\[
(a^2 |\hat{w}|^2 +\sigma^2)\hat{u} = a a^*|\hat{w}|^2e^{i\omega(\tau^*-\tau)}
\]
the solution of which is
\[
\hat{u}[m;d] \approx \frac{a^*}{a}\hat{g}_{\frac{\sigma}{a}} e^{i\omega(\tau^*-\tau)}
\]
where
$$ 
\hat{g}_{\sigma} = \frac{|\hat{w}|^2}{|\hat{w}|^2 + \sigma^2}.
$$
Transient acoustic sources are effectively bandlimited:
$\hat{w}(\omega) \rightarrow 0$ faster than any negative power of
$\omega$ as $|\omega| \rightarrow \infty$ and is entire analytic, whence $\hat{g}_{\sigma}:$ tends to $1$ almost everywhere as $\sigma \rightarrow 0$. Hence the inverse Fourier transform $g_{\sigma}$ tends to $\delta$ in the sense of distributions, and 
$$
u_{0,\sigma}[m;d](t) \approx \frac{a^*}{a}g_{\frac{\sigma}{a}}(t-(\tau^*-\tau))
$$
to a multiple of a shifted $\delta$, in fact exactly the distribution
solution of $\bar{S}[m,w]u=d$ given in equation \ref{eqn:notl2}. However for $\sigma>0$, $u_{0,\sigma}[m;d]$ is square integrable.

\cite{HuangSymes2015SEG} presented an analysis of the Matched Source
Waveform Inversion (MSWI) objective function, which is essentially the
numerator of the right hand side in the definition
\ref{eqn:tJz} of the AWI objective. This analysis was based in turn on ideas presented in Song's thesis
\cite[]{Song:94c}. MSWI deals with the extended source $\bar{w}$, but
the same construction applies to the adaptive filter $u$. With $u$ replaced by $u_{0,\sigma}[m;d]$,  the MSWI objective is
\[
J_{\rm MSWI}[m;d] = \int dt |tu_{0,\sigma}[m;d]|^2 \approx \frac{(a^*)^2}{a^2} \int dt\, t^2|g_{\frac{\sigma}{a}}(t-(\tau^*-\tau))|^2
\]
\[
=\frac{(a^*)^2}{a^2} \int dt\, (t+(\tau^*-\tau))^2|g_{\frac{\sigma}{a}}(t)|^2
\]
\begin{equation}
  \label{eqn:MSWI}
  =\frac{(a^*)^2}{a^2} \int dt\, (t^2 + 2t
  (\tau^*-\tau)+(\tau^*-\tau)^2)|g_{\frac{\sigma}{a}}(t)|^2
\end{equation}
As noted by \cite{HuangSymes2015SEG}, the linear term (in t) on the
right-hand side of \ref{eqn:MSWI} vanishes,
since $g$ is necessarily even in time (since its Fourier transform is
real). So
\begin{equation}
  \label{eqn:MSWIasym}
  J_{\rm MSWI}[m;d] \approx
\frac{(a^*)^2}{a^2} \int dt\, t^2|g_{\frac{\sigma}{a}}(t)|^2
+(\tau^*-\tau)^2\frac{(a^*)^2}{a^2}\|g_{\frac{\sigma}{a}}\|^2
\end{equation}
The first term tends to zero as $\sigma \rightarrow 0$, since
$g_{\sigma}$ is a delta-family, so you can make it negligible with
proper choice of $\sigma$. The second term suggests that this function
is related to the travel-time error $\tau^*-\tau$.

The relation is obscured by the presence of of the amplitudes
$a^*, a$ both in the multiplier and in the scaling of $\sigma$. Since the
amplitudes depend on $m$, their presence may influence the location
(or even the presence) of stationary points of $J_{\rm MSWI}$ for
models differing in their travel time predictions. So stationary
points of the MSWI objective may not yield slowness models that match
travel-times with the data, even in the noise-free case (though
the examples reported by \cite{HuangSymes2015SEG, HuangSymes:Geo17}, and other works
cited there, suggest that sometimes this is the case).

Comparing the definitions \ref{eqn:tJz} of $J_{\rm AWI}$ and
\ref{eqn:MSWI} of $J_{\rm MSWI}$, ones sees
that the two functions differ only by the factor $\|u_{0,\sigma}[m;d]\|^{-2}$ in
the former. Using the geometric asymptotics approximation, 
$$
\|u_{0,\sigma}[m;d]\| \approx \frac{a^*}{a}\|g_{\frac{\sigma}{a}}\| + O(\sigma^2)
$$
Therefore, multiplication of the MSWI objective by $\|u_{0,\sigma}[m;d]\|^{-2}$
precisely removes the amplitude factor in the right-hand side of the
relation \ref{eqn:MSWIasym}. Restoring the source and receiver
coordinates to the notation,
$$
J_{\rm AWI}[m;d] \approx \sum_{{\bf x}_s,{\bf x}_r} (\tau[m^*]({\bf
  x}_s,{\bf x}_r)-\tau[m]({\bf x}_s,{\bf x}_r))^2 + O(\sigma^2)
$$
In other words, the AWI objective is {\em exactly} an approximation to
the travel-time tomography objective, with errors proportional to the
``wavelength'' $\lambda(w)$ and the regularization parameter
$\sigma^2$.

And that's ``why it works'' - when geometric asymptotics in the form
given by equation \ref{eqn:hadamard} is an accurate approximation to the Green's function.

\section{Relation to Penalty Formulation}
Penalty functions provide a means to convert naively posed
inverse problems into well-posed problems, with solutions that exist
and depend stably on proper data. The ``pre-whitening'' construction
explained in the last section is a classic example, adding a scaled
mean-square of the adaptive filter to the residual mean-square to
produce an objective with a square-integrable (finite-energy)
minimizer. This penalty construction if often called {\em Tihonov
  regularization}. The MSWI and AWI objective functions have a deeper
relation to a penalty construction, however: they are
suitably defined limits of penalty functions.

This relation is abstract, and does not just pertain to the problems
discussed in this paper. To derive this abstract relation, suppose for
the moment that $S:U \rightarrow D$ is a bounded and coercive from a
domain Hilbert space $U$ to a range Hilbert space $D$. That is, for
real numbers $0 < C_* \le C^*$,
\[
  C_*\|u\|_U \le \|Su\|_D \le C^*\|u\|
\]
Suppose that $d \in D$ (``data''), and $T$ is another bounded operator $U \rightarrow E$, $E$
another Hilbert space. Define
\begin{equation}
  \label{eqn:eq1}
  J_{\alpha}(u) = \frac{1}{2}(\|Su-d\|_D + \alpha^2\|Tu\|_E^2).
\end{equation}
and
\begin{equation}
  \label{eqn:eq0}
  \tJa= \min_u J_{\alpha}(u) = J_{\alpha}(u_{\alpha})
\end{equation}
Since $S$ is coercive, the minimum is well-defined for any
$\alpha \ge 0$, and the minimizer $\ua \in U$ satisfies the normal
equation
\begin{equation}
  \label{eqn:eq0n}
  (S^TS + \alpha^2 T^TT) \ua = S^Td
\end{equation}

The claim to be established is that
\begin{equation}
  \label{eqn:eq4}
  \lim_{\alpha \rightarrow 0} \frac{1}{\alpha^2}  (\tJa-\tJz).= \frac{1}{2}\|T\uz\|^2
\end{equation}

To see this, use the normal equation to write
\[
  \ua = (S^TS + \alpha^2 T^TT)^{-1}T^Td = (S^TS + \alpha^2 T^TT)^{-1}S^TS \uz
\]
\begin{equation}
  \label{eqn:eq2}
  = \uz - \alpha^2 (S^TS + \alpha^2 T^TT)^{-1}T^TT\uz = \uz-\alpha^2 \va
\end{equation}
Note that $\va = (S^TS + \alpha^2 T^TT)^{-1}T^TT\uz$ is uniformly bounded in $\alpha \ge 0$.

Substitute the RHS of equation \ref{eqn:eq2} into the definition \ref{eqn:eq1} to obtain
\begin{equation}
  \label{eqn:eq3}
  \tJa = \frac{1}{2}(\|S\uz-d\|_d^2 - 2 \alpha^2\langle S\uz-d, S\va\rangle_d + \alpha^2\|T\uz\|_m^2 + O(\alpha^4))
\end{equation}
The second term on the RHS of equation \ref{eqn:eq3} vanishes thanks to the normal equation, and the first term is precisely $\tJz$. The conclusion \ref{eqn:eq4} follows.

To apply the assertion \ref{eqn:eq4} to the MSWI objective, make the
following choices, for each $m$ in the domain of $F$: $S$ is the regularized
modeling operator $(S[m],\sigma I)^T$.  Its domain is $U=L^2(\bR)$, of
which $u$ (the adaptive filter) is a member, and 
its range is $D = L^2(\bR) \oplus
L^2(\bR)$. The role of $d$ is played  the
augmented data $(d,0)^T$. $T$ is a modified multiply-by-$t$ operator
$Tu(t)=\max(|t|, t_{\rm max}) \mbox{sgn}(t)u(t)$, with domain $U$ and
range $E=L^2(\bR)$. The truncation by $t_{\rm max} > 0$ is necessary
to make $T$ bounded, but can be chosen large enough relative to the
support of the filter (necessarily bounded in practical calculation)
to have no effect. Then $\Ja$ becomes $J_{{\rm MSWI},\alpha,\sigma}[m,u;d]$, where
\begin{equation}
  \label{eqn:eq5}
   J_{{\rm MSWI},\alpha,\sigma}[m,u;d] = \frac{1}{2}\left(\|S[m]u-d\|^2 +
   \sigma^2\|u\|^2 + \alpha^2\|Tu\|^2\right)
 \end{equation}
The minimizer $\ua$ over $u$ of $ J_{{\rm MSWI}, \alpha,\sigma}[m,u;d]$ is
$u_{{\rm MSWI},\alpha,\sigma}[m;d]$, and $\tJa$ becomes
\begin{equation}
  \label{eqn:eq6}
  \tilde{J}_{{\rm MSWI},\alpha,\sigma}[m;d] =
  J_{{\rm MSWI},\alpha,\sigma}[m,u_{{\rm MSWI},\alpha,\sigma}[m;d];d].
\end{equation}
Note that $u_0$ becomes $u_{0,\sigma}[m;d]$, and $\tilde{J}_0$ becomes
$\tilde{J}_{0,\sigma}[m;d]$ which means exactly what
it did in the previous section. The subscript ${\rm MSWI}$ is left
off for $\alpha=0$, for reasons that will become apparent shortly.

With these correspondences, equation \ref{eqn:eq4} becomes
\begin{equation}
  \label{eq7}
  \lim_{\alpha \rightarrow 0}
  \frac{1}{\alpha^2}\left(\tilde{J}_{{\rm MSWI},\alpha,\sigma}[m;d]-\tilde{J}_{0,\sigma}[m;d]\right)=
  J_{\rm MSWI}[m;d]
\end{equation}

To derive the analogous relation for AWI only requires re-definition
of the operator $T$: it becomes (taking explicitly into account
dependence on source and receiver coordinates)
\begin{equation}
  \label{eqn:eq8}
  T[m;d] u(\bx_r,t;\bx_s) = \frac{\max(|t|, t_{\rm max})
    \mbox{sgn}(t)}{\|u_{0,\sigma}[m;d](\bx_r,\cdot;\bx_s)\|}
  u(\bx_r,t;\bx_s).
\end{equation}
That is, for AWI, $T$ depends on both model and data. Define
\begin{equation}
  \label{eqn:eq5a}
   J_{{\rm AWI},\alpha,\sigma}[m,u;d] = \frac{1}{2}\left(\|S[m]u-d\|^2 +
   \sigma^2\|u\|^2 + \alpha^2\|T[m;d]u\|^2\right)
 \end{equation}
The minimizer $\ua$ over $u$ of $ J_{{\rm AWI}, \alpha,\sigma}[m,u;d]$ is
$u_{{\rm AWI},\alpha,\sigma}[m;d]$, and $\tJa$ becomes
\begin{equation}
  \label{eqn:eq6a}
  \tilde{J}_{{\rm AWI},\alpha,\sigma}[m;d] =
  J_{{\rm AWI};\alpha,\sigma}[m,u_{{\rm AWI};\alpha,\sigma}[m;d];d].
\end{equation}
Note that the definitions \ref{eqn:eq5} and \ref{eqn:eq6} are exactly
the same as the corresponding definition \ref{eqn:eq5a} and
\ref{eqn:eq6a} when $\sigma=0$, which is why the subscripts ${\rm
  MSWI}$ and ${\rm AWI}$ are left off in these cases.

Precisely the
same reasoning then leads to
\begin{equation}
  \label{eq9}
  \lim_{\alpha \rightarrow 0}
  \frac{1}{\alpha^2}\left(\tilde{J}_{{\rm AWI},\alpha,\sigma}[m;d]-\tilde{J}_{0,\sigma}[m;d]\right)=
  J_{\rm AWI}[m;d]
\end{equation}

\section{Multiple Arrivals and Cycle-Skipping}
The geometric asymptotics approximation \ref{eqn:hadamard} holds only
in the ``single arrival'' case, that is, when sources and receivers
are close enough together relative to the length scale of significant
variation in the wave velocity $((\kappa\beta)^{1/2})$ that a unique ray of
geometric acoustics connects each source-receiver pair. At larger
distances, multiple raypaths typically exist, corresponding to
multiple idenfiable wavefront arrivals. Accordingly, in such settings
the analysis presented in the last section no longer applies, and the
relation established there between AWI and travel-time inversion is
case into doubt.

In fact, the behaviour inherited from travel-time inversion in the
single arrival case, namely the absence of spurious stationary points
(``cycle-skipping''), generally fails when multiple arrivals with
significant energy are present in the data. \cite{Symes:94c}
illustrated this phenomenon for a version of MSWI. Crosswell
source-receiver geometry often generates multiple arrivals,
particularly near low-velocity sedimentary layers that are natural
targets of seismic exploration and act as wave
guides. \cite{Plessix:00} successfully applied a version of MSWI to
crosswell waveform inversion by removing traces with close source and
receiver depths, thus leaving only data that tended to be dominated by
single arrivals. \cite{HuangSymes:Geo17} illustrate the failure of the
version of MSWI reported here to avoid cycle-skipping in inversion of
strongly refracting models, and ameliorate the this failure to some
extent by Tihonov regularization. They observe that the mapping from
adaptive filter or extended source to data (represented by the opertor
$S[m]$ in the discussion above) may not have a well-behaved inverse in
the presence of multiple wavefront arrivals. \cite{Yongetal:GJI23}
have shown that precisely the same issue afflicts AWI, and have
proposed a remedy by localizing the definition of the objective to
short time intervals, within which multiple wavefront arrrivals are
unlikely. \cite{Symes:23} constructs an extension based on surface
sources, as opposed to the source-receiver extension which is the
basis of MSWI and AWI. This surface source extension generates an
invertible map from extended source to data.

A simple calculation reveals the phenomenon discussed in all of these
works. The analogue of the geometric asymptotics for a source-receiver
pair with connected by multiple rays is (once again suppressing the
source and receiver coordinates from the notation):
\begin{equation}
  \label{eqn:multi}
  F[m]w(t) \approx \sum_{i \ge 0} a_i H^{p_i}w(t-\tau_i).
\end{equation}
The amplitudes $\{a_i\}$ and arrival times $\{\tau_i\}$ depend on $m$, as
before, through ray-tracing. $H$ is the Hilbert transform, and $p_i$
counts the number of times the ray for arrival time $\tau_i$ has
touched a caustic (counted with multiplicity, in an appropriate
sense). The earliest arrival has not touched a caustic. If the
indexing is organized so that $\tau_0 < \tau_i$ for $i>0$, then
$p_0=0$. See \cite{Friedlander:75} for details.

The right-hand side of equation \ref{eqn:multi} can be expressed as
\[
  = (\delta + T) * a_0w(t-\tau_0),
\]
in which 
\[
  T = \sum_{i \ge 1}
  \frac{a_i}{a_0}H^{p_i}\delta(t-(\tau_i-\tau_0))
\]
Thus
\begin{equation}
  \label{eqn:unwrap}
  (\delta +T_1) * F[m]w \approx  a_0w(t-\tau_0)
\end{equation}
where $\delta + T_1$ is the convolution inverse of $\delta + T$,
defined by 
\[
  T_1 = \sum_{n=1}^{\infty} (-1)^n T^n.
\]
$T^n$ should be understood as the $n$th convolution power in this
expression, that is, $T*T*...*T$, $n$ times. $T_1$ is well-defined as a distribution.

Once again, it is possible to write the adaptive filter u for which $S[m]u = (F[m]w)*u = d =
F[m^*]w$ by inspection. Use the notations $a^*_i, t^*_i, p^*_i$ for
the analogous quantities computed with the ``true'' model $m^*$, and
$T^*, T_1^*$ defined as above but with $a^*_i$ in place of $a_i$ and so
on. From the observation \ref{eqn:notl2},
\[
  d = F[m_*]w = S[m]u
\]
provided that we choose
\begin{equation}
  \label{eqn:notl2again}
u(t) \approx (\delta + T^*)*(\delta +
T_1)*\left(\frac{a^*_0}{a_0}\delta(t - (\tau^*_0-\tau_0))\right)
\end{equation}
Recalling the ordering of arrival times, 
\[
  T^* = \frac{a^*_1}{a^*_0}H^{p_1^*} \delta(t-(\tau^*_1-\tau^*_0)) + ...
\]
\[
  T_1 = -\frac{a_1}{a_0}H^{p_1} \delta(t-(\tau_1-\tau_0)) + ...
\]
where the elided terms all involve $\delta$s located at later times.
So
\[
  (\delta + T^*)*(\delta + T_1)(t) = \delta(t)  +  \frac{a^*_1}{a^*_0}
  H^{p_1^*}\delta(t-(\tau^*_1-\tau^*_0)) -\frac{a_1}{a_0}H^p_1
  \delta(t-(\tau_1-\tau_0)) + ...
\]
and
\begin{equation}
  \label{eqn:notl2explicit}
  u(t) = \frac{a^*_0}{a_0}\left(\delta(t - (\tau^*_0-\tau_0)) +
    \frac{a^*_1}{a^*_0}H^{p_1^*}\delta(t-(\tau^*_1-\tau_0)) -
    \frac{a_1}{a_0}H^{p_1}\delta(t-(\tau_1-\tau_0^*)) + ...\right)
\end{equation}
The elided terms involve only travel time differences other than the
ones appearing here, so nothing cancels.

Observe that the travel-time differences $\tau^*_1-\tau_0$,
$\tau_1-\tau_0^*$ do not tend to zero, though they do tend to the same
limit as $m \rightarrow m^*$ (as do the amplitude quotients), and the
Hilbert transform powers $p_1, p_1^*$ are the same as soon as $m$ is
sufficiently close to $m^*$.

Of courese, the adaptive filter just computed is not square
integrable, and must be regularized for use in a mean-square
construction like that of AWI or MSWI. That amounts essentially to
replacing the $\delta$s in the above formulae by a square-integrable
approximate Dirac function, of roughly a wavelength in width. In the
preceding section, this approximate Dirac was $g$, so use the same
notation here. The regularized version of $u(t)$ in
\ref{eqn:notl2explicit} contains summands with multiples of $g(t-(\tau^*_1-\tau_0))$
and $g(t-(\tau_1-\tau^*_0))$. These are approximately scaled by
$\tau^*_1-\tau_0$ and $\tau_1-\tau^*_0$ respectively in the
definitions \ref{eqn:MSWI} and \ref{eqn:tJz} of the MSWI and AWI
objectives. For other choices of objective, they contribute similarly
to the total. They will eventually begin to cancel as $m$ approaches
$m^*$, however this cancellation happens only when the times are
within the width of the approximate 
Dirac waveform $g$ - that is, within a wavelength.

This argument shows that when multiple arrivals carry significant energy, any
inversion approach based on the source-receiver extension, similar to
AWI or MSWI, will cycle-skip, that is, change rapidly when the
estimated model approaches its optimal value.

It should be emphasized that this phenomenon is primarily a feature of the
source-receiver extension, rather than of the specific objective
function defined in terms of it. In that respect, the source-receiver
extension is similar to the common surface parameter extensions that
have been studied for inversion of reflection data. Inversion methods
based on these extensions also fail to avoid cycle-skipping in the presence of
geometrical ray complexity \cite[]{geoprosp:2008}.

\section{Conclusion}
In this paper, I have shown that AWI is a good approximation to least
squares travel time inversion of transmitted wave data, up to errors proportional to a typical
data wavelength and to a regularization (``pre-whitening'')
weight. However, the argument leading to this conclusion works only if
the material model is assumed slowly varying so that geometric
acoustics accurately describes the solution of the wave equation, and if
sources and receivers are sufficiently close to one another to be
connected by unique rays. The first condition may be ignored to some
extent - the conclusion of this paper likely holds if the data is
dominated by ballistic transmitted waves. The second condition
is essential: even for purely transmitted waves, the presence of
multiple arrivals breaks the connection
with travel time inversion, and AWI and similar algorithms
become essentially as prone to cycle-skipping as is FWI.

The analysis presented here has nothing to say about AWI applied to
reflected wave data. \cite{Warner:16} and others have
suggested that AWI is effective in that context. If so, the underlying
mechanism remains to be explained. 

\bibliographystyle{seg}
\bibliography{../../bib/masterref}

